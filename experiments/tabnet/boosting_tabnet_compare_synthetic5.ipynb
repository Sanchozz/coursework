{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pickle\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "from bo_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tuned = {\n",
    "    \"learning_rate\" : 0.14244374976727375, \n",
    "    \"max_depth\" : 5, \n",
    "    \"n_estimators\" : 198\n",
    "}\n",
    "# lgbm_tuned += LIGHTGBM_PARAMS\n",
    "\n",
    "xgb_tuned = {\n",
    "    \"learning_rate\" : 0.437344281810245, \n",
    "    \"max_depth\" : 5, \n",
    "    \"n_estimators\" : 920\n",
    "}\n",
    "# xgb_tuned += XGBOOST_PARAMS\n",
    "\n",
    "tabnet_tuned = {\n",
    "    \"gamma\" : 1.1227966185155351, \n",
    "    \"lambda_sparse\" : 0.05232096763520789, \n",
    "    \"n_steps\" : 4,\n",
    "    \"n_a\" : 24,\n",
    "    \"momentum\" : 0.7,\n",
    "}\n",
    "tabnet_tuned[\"n_d\"] = tabnet_tuned[\"n_a\"]\n",
    "\n",
    "tabnet_paper = {\n",
    "    \"gamma\" : 1.5, \n",
    "    \"lambda_sparse\" : 0.004, \n",
    "    \"n_steps\" : 5,\n",
    "    \"n_a\" : 16,\n",
    "    \"momentum\" : 0.7,\n",
    "}\n",
    "tabnet_paper[\"n_d\"] = tabnet_paper[\"n_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/synthetic/syn5/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/synthetic/syn5/train.csv\")\n",
    "valid = pd.read_csv(\"data/synthetic/syn5/val.csv\")\n",
    "test = pd.read_csv(\"data/synthetic/syn5/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325858</td>\n",
       "      <td>0.697184</td>\n",
       "      <td>0.812222</td>\n",
       "      <td>2.140518</td>\n",
       "      <td>0.325858</td>\n",
       "      <td>0.697184</td>\n",
       "      <td>0.812222</td>\n",
       "      <td>2.140518</td>\n",
       "      <td>1.223960</td>\n",
       "      <td>0.188322</td>\n",
       "      <td>-4.019868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170500</td>\n",
       "      <td>-0.241799</td>\n",
       "      <td>-0.679737</td>\n",
       "      <td>0.770884</td>\n",
       "      <td>-1.049472</td>\n",
       "      <td>1.308436</td>\n",
       "      <td>-0.390377</td>\n",
       "      <td>-0.395647</td>\n",
       "      <td>-1.141868</td>\n",
       "      <td>1.099354</td>\n",
       "      <td>3.645112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.653021</td>\n",
       "      <td>-0.696606</td>\n",
       "      <td>0.518960</td>\n",
       "      <td>-0.436847</td>\n",
       "      <td>-0.653021</td>\n",
       "      <td>-0.696606</td>\n",
       "      <td>0.518960</td>\n",
       "      <td>-0.436847</td>\n",
       "      <td>0.302409</td>\n",
       "      <td>-0.050042</td>\n",
       "      <td>-2.493129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.850964</td>\n",
       "      <td>-1.965242</td>\n",
       "      <td>-0.200949</td>\n",
       "      <td>1.125162</td>\n",
       "      <td>0.507335</td>\n",
       "      <td>-1.004379</td>\n",
       "      <td>-0.099335</td>\n",
       "      <td>-1.313870</td>\n",
       "      <td>-0.686837</td>\n",
       "      <td>1.209220</td>\n",
       "      <td>3.551766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.407988</td>\n",
       "      <td>-1.312217</td>\n",
       "      <td>0.364332</td>\n",
       "      <td>-0.865937</td>\n",
       "      <td>0.982733</td>\n",
       "      <td>0.056740</td>\n",
       "      <td>-2.006299</td>\n",
       "      <td>-0.185867</td>\n",
       "      <td>-0.120750</td>\n",
       "      <td>1.283596</td>\n",
       "      <td>3.424538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0  0.325858  0.697184  0.812222  2.140518  0.325858  0.697184  0.812222   \n",
       "1 -0.170500 -0.241799 -0.679737  0.770884 -1.049472  1.308436 -0.390377   \n",
       "2 -0.653021 -0.696606  0.518960 -0.436847 -0.653021 -0.696606  0.518960   \n",
       "3  0.850964 -1.965242 -0.200949  1.125162  0.507335 -1.004379 -0.099335   \n",
       "4 -0.407988 -1.312217  0.364332 -0.865937  0.982733  0.056740 -2.006299   \n",
       "\n",
       "         X7        X8        X9       X10  TARGET  \n",
       "0  2.140518  1.223960  0.188322 -4.019868       0  \n",
       "1 -0.395647 -1.141868  1.099354  3.645112       0  \n",
       "2 -0.436847  0.302409 -0.050042 -2.493129       0  \n",
       "3 -1.313870 -0.686837  1.209220  3.551766       1  \n",
       "4 -0.185867 -0.120750  1.283596  3.424538       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop([\"TARGET\"], axis=1)\n",
    "train_y = train[\"TARGET\"]\n",
    "\n",
    "test_X = test.drop([\"TARGET\"], axis=1)\n",
    "test_y = test[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.14244374976727375, max_depth=5, metric='auc',\n",
       "               n_estimators=198, objective='binary', random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier(**{**lgbm_tuned, **LIGHTGBM_PARAMS})\n",
    "model_lgbm.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:47:55] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:47:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.437344281810245, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=920, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "model_xgb.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABNET_PARAMS[\"verbose\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.613   |  0:00:02s\n",
      "epoch 1  | loss: 0.35932 |  0:00:05s\n",
      "epoch 2  | loss: 0.28923 |  0:00:08s\n",
      "epoch 3  | loss: 0.26954 |  0:00:11s\n",
      "epoch 4  | loss: 0.25874 |  0:00:14s\n",
      "epoch 5  | loss: 0.24691 |  0:00:16s\n",
      "epoch 6  | loss: 0.23038 |  0:00:19s\n",
      "epoch 7  | loss: 0.21716 |  0:00:22s\n",
      "epoch 8  | loss: 0.19493 |  0:00:24s\n",
      "epoch 9  | loss: 0.19753 |  0:00:27s\n",
      "epoch 10 | loss: 0.18879 |  0:00:30s\n",
      "epoch 11 | loss: 0.18524 |  0:00:33s\n",
      "epoch 12 | loss: 0.1665  |  0:00:36s\n",
      "epoch 13 | loss: 0.16408 |  0:00:38s\n",
      "epoch 14 | loss: 0.16328 |  0:00:41s\n",
      "epoch 15 | loss: 0.15696 |  0:00:44s\n",
      "epoch 16 | loss: 0.14464 |  0:00:46s\n",
      "epoch 17 | loss: 0.14058 |  0:00:49s\n",
      "epoch 18 | loss: 0.13811 |  0:00:52s\n",
      "epoch 19 | loss: 0.13061 |  0:00:55s\n",
      "epoch 20 | loss: 0.13601 |  0:00:57s\n",
      "epoch 21 | loss: 0.13296 |  0:01:00s\n",
      "epoch 22 | loss: 0.12688 |  0:01:03s\n",
      "epoch 23 | loss: 0.13014 |  0:01:06s\n",
      "epoch 24 | loss: 0.11896 |  0:01:09s\n",
      "epoch 25 | loss: 0.12112 |  0:01:11s\n",
      "epoch 26 | loss: 0.1259  |  0:01:14s\n",
      "epoch 27 | loss: 0.11847 |  0:01:17s\n",
      "epoch 28 | loss: 0.12182 |  0:01:20s\n",
      "epoch 29 | loss: 0.12475 |  0:01:22s\n",
      "epoch 30 | loss: 0.11674 |  0:01:25s\n",
      "epoch 31 | loss: 0.11445 |  0:01:28s\n",
      "epoch 32 | loss: 0.11991 |  0:01:31s\n",
      "epoch 33 | loss: 0.12055 |  0:01:33s\n",
      "epoch 34 | loss: 0.12004 |  0:01:37s\n",
      "epoch 35 | loss: 0.12036 |  0:01:39s\n",
      "epoch 36 | loss: 0.11918 |  0:01:41s\n",
      "epoch 37 | loss: 0.1128  |  0:01:42s\n",
      "epoch 38 | loss: 0.12257 |  0:01:43s\n",
      "epoch 39 | loss: 0.11271 |  0:01:44s\n",
      "epoch 40 | loss: 0.10553 |  0:01:45s\n",
      "epoch 41 | loss: 0.11256 |  0:01:46s\n",
      "epoch 42 | loss: 0.11434 |  0:01:48s\n",
      "epoch 43 | loss: 0.1129  |  0:01:49s\n",
      "epoch 44 | loss: 0.10945 |  0:01:50s\n",
      "epoch 45 | loss: 0.10811 |  0:01:51s\n",
      "epoch 46 | loss: 0.10686 |  0:01:52s\n",
      "epoch 47 | loss: 0.10641 |  0:01:54s\n",
      "epoch 48 | loss: 0.10253 |  0:01:55s\n",
      "epoch 49 | loss: 0.10664 |  0:01:56s\n",
      "epoch 50 | loss: 0.10844 |  0:01:57s\n",
      "epoch 51 | loss: 0.10506 |  0:01:58s\n",
      "epoch 52 | loss: 0.10544 |  0:02:00s\n",
      "epoch 53 | loss: 0.10785 |  0:02:01s\n",
      "epoch 54 | loss: 0.11444 |  0:02:02s\n",
      "epoch 55 | loss: 0.11135 |  0:02:03s\n",
      "epoch 56 | loss: 0.11627 |  0:02:04s\n",
      "epoch 57 | loss: 0.10881 |  0:02:06s\n",
      "epoch 58 | loss: 0.10434 |  0:02:07s\n",
      "epoch 59 | loss: 0.10011 |  0:02:08s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS})\n",
    "model_tabnet.fit(train_X.values, train_y.values, max_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.95103 |  0:00:01s\n",
      "epoch 1  | loss: 0.60275 |  0:00:02s\n",
      "epoch 2  | loss: 0.51365 |  0:00:03s\n",
      "epoch 3  | loss: 0.46871 |  0:00:04s\n",
      "epoch 4  | loss: 0.41295 |  0:00:05s\n",
      "epoch 5  | loss: 0.38342 |  0:00:07s\n",
      "epoch 6  | loss: 0.35593 |  0:00:08s\n",
      "epoch 7  | loss: 0.35394 |  0:00:09s\n",
      "epoch 8  | loss: 0.35338 |  0:00:10s\n",
      "epoch 9  | loss: 0.33224 |  0:00:11s\n",
      "epoch 10 | loss: 0.31095 |  0:00:12s\n",
      "epoch 11 | loss: 0.29633 |  0:00:14s\n",
      "epoch 12 | loss: 0.28182 |  0:00:15s\n",
      "epoch 13 | loss: 0.28915 |  0:00:16s\n",
      "epoch 14 | loss: 0.27127 |  0:00:17s\n",
      "epoch 15 | loss: 0.27677 |  0:00:18s\n",
      "epoch 16 | loss: 0.27018 |  0:00:19s\n",
      "epoch 17 | loss: 0.2659  |  0:00:20s\n",
      "epoch 18 | loss: 0.26884 |  0:00:22s\n",
      "epoch 19 | loss: 0.25313 |  0:00:23s\n",
      "epoch 20 | loss: 0.25226 |  0:00:24s\n",
      "epoch 21 | loss: 0.26214 |  0:00:25s\n",
      "epoch 22 | loss: 0.24876 |  0:00:26s\n",
      "epoch 23 | loss: 0.24192 |  0:00:27s\n",
      "epoch 24 | loss: 0.24777 |  0:00:29s\n",
      "epoch 25 | loss: 0.24478 |  0:00:30s\n",
      "epoch 26 | loss: 0.24403 |  0:00:31s\n",
      "epoch 27 | loss: 0.24014 |  0:00:32s\n",
      "epoch 28 | loss: 0.23944 |  0:00:33s\n",
      "epoch 29 | loss: 0.23941 |  0:00:35s\n",
      "epoch 30 | loss: 0.22873 |  0:00:36s\n",
      "epoch 31 | loss: 0.22585 |  0:00:37s\n",
      "epoch 32 | loss: 0.21715 |  0:00:38s\n",
      "epoch 33 | loss: 0.21961 |  0:00:39s\n",
      "epoch 34 | loss: 0.21878 |  0:00:40s\n",
      "epoch 35 | loss: 0.21655 |  0:00:41s\n",
      "epoch 36 | loss: 0.21278 |  0:00:43s\n",
      "epoch 37 | loss: 0.205   |  0:00:44s\n",
      "epoch 38 | loss: 0.20299 |  0:00:45s\n",
      "epoch 39 | loss: 0.18931 |  0:00:46s\n",
      "epoch 40 | loss: 0.1945  |  0:00:47s\n",
      "epoch 41 | loss: 0.18715 |  0:00:48s\n",
      "epoch 42 | loss: 0.17869 |  0:00:50s\n",
      "epoch 43 | loss: 0.18471 |  0:00:51s\n",
      "epoch 44 | loss: 0.18115 |  0:00:52s\n",
      "epoch 45 | loss: 0.17631 |  0:00:53s\n",
      "epoch 46 | loss: 0.17093 |  0:00:54s\n",
      "epoch 47 | loss: 0.1801  |  0:00:55s\n",
      "epoch 48 | loss: 0.1669  |  0:00:57s\n",
      "epoch 49 | loss: 0.16523 |  0:00:58s\n",
      "epoch 50 | loss: 0.15701 |  0:00:59s\n",
      "epoch 51 | loss: 0.15385 |  0:01:00s\n",
      "epoch 52 | loss: 0.14607 |  0:01:01s\n",
      "epoch 53 | loss: 0.14784 |  0:01:02s\n",
      "epoch 54 | loss: 0.15064 |  0:01:03s\n",
      "epoch 55 | loss: 0.15248 |  0:01:05s\n",
      "epoch 56 | loss: 0.13987 |  0:01:06s\n",
      "epoch 57 | loss: 0.14642 |  0:01:07s\n",
      "epoch 58 | loss: 0.15134 |  0:01:08s\n",
      "epoch 59 | loss: 0.14544 |  0:01:09s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet_paper = TabNetClassifier(**{**tabnet_paper, **TABNET_PARAMS})\n",
    "model_tabnet_paper.fit(train_X.values, train_y.values, max_epochs=60, batch_size=3000, virtual_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet, f)\n",
    "with open('model_tabnet_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet_paper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'rb') as f:\n",
    "    model_tabnet = pickle.load(f)\n",
    "with open('model_tabnet_paper.pickle', 'rb') as f:\n",
    "    model_tabnet_paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM auc:  0.994257\n",
      "XGBoost auc:  0.99333\n",
      "TabNet auc:  0.992631\n",
      "TabNet Paper auc:  0.985884\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM auc: \", round(roc_auc_score(test_y, model_lgbm.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"XGBoost auc: \", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"TabNet auc: \", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X.values)[:, 1]), 6))\n",
    "print(\"TabNet Paper auc: \", round(roc_auc_score(test_y, model_tabnet_paper.predict_proba(test_X.values)[:, 1]), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM acc:  0.972019\n",
      "XGBoost acc:  0.972685\n",
      "TabNet acc:  0.968688\n",
      "TabNet Paper acc:  0.944704\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM acc: \", round(accuracy_score(test_y, model_lgbm.predict(test_X)), 6))\n",
    "print(\"XGBoost acc: \", round(accuracy_score(test_y, model_xgb.predict(test_X)), 6))\n",
    "print(\"TabNet acc: \", round(accuracy_score(test_y, model_tabnet.predict(test_X.values)), 6))\n",
    "print(\"TabNet Paper acc: \", round(accuracy_score(test_y, model_tabnet_paper.predict(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM log_loss:  0.091783\n",
      "XGBoost log_loss:  0.120335\n",
      "TabNet log_loss:  0.089274\n",
      "TabNet Paper log_loss:  0.144407\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM log_loss: \", round(log_loss(test_y, model_lgbm.predict_proba(test_X)), 6))\n",
    "print(\"XGBoost log_loss: \", round(log_loss(test_y, model_xgb.predict_proba(test_X)), 6))\n",
    "print(\"TabNet log_loss: \", round(log_loss(test_y, model_tabnet.predict_proba(test_X.values)), 6))\n",
    "print(\"TabNet Paper log_loss: \", round(log_loss(test_y, model_tabnet_paper.predict_proba(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = list(enumerate(model_lgbm.feature_importances_))\n",
    "importance_xgb = model_xgb.get_booster().get_score(importance_type='weight').items()\n",
    "importance_tabnet = list(enumerate(model_tabnet.feature_importances_))\n",
    "importance_tabnet_paper = list(enumerate(model_tabnet_paper.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = sorted(importance_lgbm, key=lambda x: x[1], reverse=True)\n",
    "importance_xgb = sorted(importance_xgb, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet = sorted(importance_tabnet, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet_paper = sorted(importance_tabnet_paper, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x424.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = shap.TreeExplainer(model_xgb).shap_values(train_X)\n",
    "shap.summary_plot(shap_values, train_X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame([train.columns[x[0]] for x in importance_lgbm], columns=[\"LightGBM\"])\n",
    "df_compare[\"XGBoost\"] = [x[0] for x in importance_xgb]\n",
    "df_compare[\"SHAP_XGBoost\"] = train_X.columns[np.argsort(np.abs(shap_values).mean(0))][::-1]\n",
    "df_compare[\"TabNet\"] = [train.columns[x[0]] for x in importance_tabnet]\n",
    "df_compare[\"TabNet_Paper\"] = [train.columns[x[0]] for x in importance_tabnet_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X0</td>\n",
       "      <td>X1</td>\n",
       "      <td>X6</td>\n",
       "      <td>X1</td>\n",
       "      <td>X6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X10</td>\n",
       "      <td>X0</td>\n",
       "      <td>X2</td>\n",
       "      <td>X6</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X2</td>\n",
       "      <td>X9</td>\n",
       "      <td>X1</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X6</td>\n",
       "      <td>X8</td>\n",
       "      <td>X0</td>\n",
       "      <td>X2</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X8</td>\n",
       "      <td>X2</td>\n",
       "      <td>X7</td>\n",
       "      <td>X5</td>\n",
       "      <td>X5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X9</td>\n",
       "      <td>X3</td>\n",
       "      <td>X8</td>\n",
       "      <td>X7</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X5</td>\n",
       "      <td>X5</td>\n",
       "      <td>X3</td>\n",
       "      <td>X3</td>\n",
       "      <td>X7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X4</td>\n",
       "      <td>X7</td>\n",
       "      <td>X5</td>\n",
       "      <td>X4</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X7</td>\n",
       "      <td>X6</td>\n",
       "      <td>X9</td>\n",
       "      <td>X9</td>\n",
       "      <td>X4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X3</td>\n",
       "      <td>X4</td>\n",
       "      <td>X4</td>\n",
       "      <td>X8</td>\n",
       "      <td>X8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM XGBoost SHAP_XGBoost TabNet TabNet_Paper\n",
       "0        X1     X10          X10    X10          X10\n",
       "1        X0      X1           X6     X1           X6\n",
       "2       X10      X0           X2     X6           X1\n",
       "3        X2      X9           X1     X0           X0\n",
       "4        X6      X8           X0     X2           X2\n",
       "5        X8      X2           X7     X5           X5\n",
       "6        X9      X3           X8     X7           X9\n",
       "7        X5      X5           X3     X3           X7\n",
       "8        X4      X7           X5     X4           X3\n",
       "9        X7      X6           X9     X9           X4\n",
       "10       X3      X4           X4     X8           X8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:2, col1]) & set(df_compare.loc[:2, col2])))\n",
    "        top_3.append(d)\n",
    "top_3_data = pd.DataFrame(top_3, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             3             1       2             2        3\n",
       "SHAP_XGBoost         1             3       2             2        1\n",
       "TabNet               2             2       3             3        2\n",
       "TabNet_Paper         2             2       3             3        2\n",
       "XGBoost              3             1       2             2        3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 3 признака из каждой и обучить бустинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:4, col1]) & set(df_compare.loc[:4, col2])))\n",
    "        top_5.append(d)\n",
    "top_5_data = pd.DataFrame(top_5, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             5             5       5             5        3\n",
       "SHAP_XGBoost         5             5       5             5        3\n",
       "TabNet               5             5       5             5        3\n",
       "TabNet_Paper         5             5       5             5        3\n",
       "XGBoost              3             3       3             3        5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_5_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:9, col1]) & set(df_compare.loc[:9, col2])))\n",
    "        top_10.append(d)\n",
    "top_10_data = pd.DataFrame(top_10, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM            10             9       9             9        9\n",
       "SHAP_XGBoost         9            10       9             9       10\n",
       "TabNet               9             9      10            10        9\n",
       "TabNet_Paper         9             9      10            10        9\n",
       "XGBoost              9            10       9             9       10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_feats = {}\n",
    "top3_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\"]\n",
    "top3_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\"]\n",
    "top3_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_feats = {}\n",
    "top10_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\", \"occupation\", \"education_num\", \"capital_gain\", \"education\", \"workclass\", \"capital_loss\", \"native_country\"]\n",
    "top10_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\", \"relationship\", \"education_num\", \"occupation\", \"fnlwgt\", \"hours_per_week\", \"sex\", \"capital_loss\"]\n",
    "top10_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\", \"hours_per_week\", \"education_num\", \"capital_gain\", \"education\", \"sex\", \"workclass\", \"capital_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-817f43cedb3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop3_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop3_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcat_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "top3_results = []\n",
    "for model, feats in top3_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([train.columns[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top3_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top3_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top3_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top3_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_scores = pd.DataFrame(top3_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.805527</td>\n",
       "      <td>0.851631</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.864625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.824770</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.857539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.769089</td>\n",
       "      <td>0.751890</td>\n",
       "      <td>0.760491</td>\n",
       "      <td>0.727796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.805527  0.851631  0.819652  0.864625\n",
       "tabnet    0.824770  0.864272  0.819652  0.857539\n",
       "xgboost   0.769089  0.751890  0.760491  0.727796"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.79592 |  0:00:12s\n",
      "epoch 1  | loss: 0.49582 |  0:00:25s\n",
      "epoch 2  | loss: 0.44158 |  0:00:40s\n",
      "epoch 3  | loss: 0.40275 |  0:00:53s\n",
      "epoch 4  | loss: 0.40626 |  0:01:05s\n",
      "epoch 5  | loss: 0.4009  |  0:01:18s\n",
      "epoch 6  | loss: 0.39774 |  0:01:30s\n",
      "epoch 7  | loss: 0.39294 |  0:01:43s\n",
      "epoch 8  | loss: 0.3906  |  0:01:57s\n",
      "epoch 9  | loss: 0.39566 |  0:02:17s\n",
      "epoch 10 | loss: 0.3941  |  0:02:54s\n",
      "epoch 11 | loss: 0.39292 |  0:03:31s\n",
      "epoch 12 | loss: 0.39145 |  0:04:11s\n",
      "epoch 13 | loss: 0.3886  |  0:04:34s\n",
      "epoch 14 | loss: 0.39061 |  0:05:00s\n",
      "epoch 15 | loss: 0.39403 |  0:05:23s\n",
      "epoch 16 | loss: 0.38763 |  0:05:47s\n",
      "epoch 17 | loss: 0.38817 |  0:06:08s\n",
      "epoch 18 | loss: 0.39708 |  0:06:32s\n",
      "epoch 19 | loss: 0.39374 |  0:06:56s\n",
      "epoch 20 | loss: 0.3895  |  0:07:21s\n",
      "epoch 21 | loss: 0.38912 |  0:07:45s\n",
      "epoch 22 | loss: 0.38642 |  0:08:08s\n",
      "epoch 23 | loss: 0.3847  |  0:08:33s\n",
      "epoch 24 | loss: 0.38419 |  0:08:57s\n",
      "epoch 25 | loss: 0.38397 |  0:09:20s\n",
      "epoch 26 | loss: 0.38094 |  0:09:44s\n",
      "epoch 27 | loss: 0.38124 |  0:10:07s\n",
      "epoch 28 | loss: 0.38337 |  0:10:31s\n",
      "epoch 29 | loss: 0.38498 |  0:10:55s\n",
      "epoch 30 | loss: 0.38105 |  0:11:19s\n",
      "epoch 31 | loss: 0.38232 |  0:11:40s\n",
      "epoch 32 | loss: 0.3815  |  0:12:04s\n",
      "epoch 33 | loss: 0.38328 |  0:12:26s\n",
      "epoch 34 | loss: 0.37821 |  0:12:49s\n",
      "epoch 35 | loss: 0.3803  |  0:13:13s\n",
      "epoch 36 | loss: 0.37915 |  0:13:36s\n",
      "epoch 37 | loss: 0.37989 |  0:13:59s\n",
      "epoch 38 | loss: 0.39247 |  0:14:23s\n",
      "epoch 39 | loss: 0.3804  |  0:14:46s\n",
      "epoch 40 | loss: 0.37794 |  0:15:11s\n",
      "epoch 41 | loss: 0.37671 |  0:15:32s\n",
      "epoch 42 | loss: 0.37527 |  0:15:54s\n",
      "epoch 43 | loss: 0.37477 |  0:16:15s\n",
      "epoch 44 | loss: 0.38458 |  0:16:38s\n",
      "epoch 45 | loss: 0.38768 |  0:17:00s\n",
      "epoch 46 | loss: 0.37762 |  0:17:25s\n",
      "epoch 47 | loss: 0.37628 |  0:17:48s\n",
      "epoch 48 | loss: 0.37779 |  0:18:10s\n",
      "epoch 49 | loss: 0.37808 |  0:18:33s\n",
      "epoch 50 | loss: 0.37675 |  0:18:56s\n",
      "epoch 51 | loss: 0.37481 |  0:19:20s\n",
      "epoch 52 | loss: 0.37458 |  0:19:43s\n",
      "epoch 53 | loss: 0.37851 |  0:20:06s\n",
      "epoch 54 | loss: 0.37758 |  0:20:30s\n",
      "epoch 55 | loss: 0.38001 |  0:20:51s\n",
      "epoch 56 | loss: 0.38308 |  0:21:15s\n",
      "epoch 57 | loss: 0.38137 |  0:21:39s\n",
      "epoch 58 | loss: 0.37925 |  0:22:01s\n",
      "epoch 59 | loss: 0.38585 |  0:22:24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:08] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:42:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.90432 |  0:00:23s\n",
      "epoch 1  | loss: 0.39276 |  0:00:49s\n",
      "epoch 2  | loss: 0.34943 |  0:01:11s\n",
      "epoch 3  | loss: 0.34461 |  0:01:34s\n",
      "epoch 4  | loss: 0.34024 |  0:01:57s\n",
      "epoch 5  | loss: 0.34186 |  0:02:20s\n",
      "epoch 6  | loss: 0.34383 |  0:02:42s\n",
      "epoch 7  | loss: 0.33729 |  0:03:08s\n",
      "epoch 8  | loss: 0.33883 |  0:03:30s\n",
      "epoch 9  | loss: 0.33975 |  0:03:54s\n",
      "epoch 10 | loss: 0.34485 |  0:04:17s\n",
      "epoch 11 | loss: 0.33227 |  0:04:40s\n",
      "epoch 12 | loss: 0.33144 |  0:05:06s\n",
      "epoch 13 | loss: 0.3314  |  0:05:29s\n",
      "epoch 14 | loss: 0.33928 |  0:05:50s\n",
      "epoch 15 | loss: 0.32989 |  0:06:12s\n",
      "epoch 16 | loss: 0.33309 |  0:06:33s\n",
      "epoch 17 | loss: 0.33441 |  0:06:56s\n",
      "epoch 18 | loss: 0.33631 |  0:07:21s\n",
      "epoch 19 | loss: 0.32965 |  0:07:44s\n",
      "epoch 20 | loss: 0.33031 |  0:08:08s\n",
      "epoch 21 | loss: 0.32679 |  0:08:31s\n",
      "epoch 22 | loss: 0.32387 |  0:08:53s\n",
      "epoch 23 | loss: 0.32129 |  0:09:18s\n",
      "epoch 24 | loss: 0.3256  |  0:09:40s\n",
      "epoch 25 | loss: 0.33124 |  0:10:03s\n",
      "epoch 26 | loss: 0.32599 |  0:10:26s\n",
      "epoch 27 | loss: 0.32683 |  0:10:49s\n",
      "epoch 28 | loss: 0.32928 |  0:11:12s\n",
      "epoch 29 | loss: 0.32668 |  0:11:35s\n",
      "epoch 30 | loss: 0.32345 |  0:11:58s\n",
      "epoch 31 | loss: 0.32416 |  0:12:21s\n",
      "epoch 32 | loss: 0.32507 |  0:12:43s\n",
      "epoch 33 | loss: 0.32404 |  0:13:05s\n",
      "epoch 34 | loss: 0.32054 |  0:13:29s\n",
      "epoch 35 | loss: 0.32212 |  0:13:53s\n",
      "epoch 36 | loss: 0.32217 |  0:14:14s\n",
      "epoch 37 | loss: 0.31913 |  0:14:37s\n",
      "epoch 38 | loss: 0.32162 |  0:15:00s\n",
      "epoch 39 | loss: 0.32277 |  0:15:23s\n",
      "epoch 40 | loss: 0.31707 |  0:15:46s\n",
      "epoch 41 | loss: 0.31975 |  0:16:09s\n",
      "epoch 42 | loss: 0.3171  |  0:16:31s\n",
      "epoch 43 | loss: 0.32048 |  0:16:55s\n",
      "epoch 44 | loss: 0.32208 |  0:17:17s\n",
      "epoch 45 | loss: 0.31896 |  0:17:41s\n",
      "epoch 46 | loss: 0.31771 |  0:18:03s\n",
      "epoch 47 | loss: 0.32248 |  0:18:25s\n",
      "epoch 48 | loss: 0.31958 |  0:18:48s\n",
      "epoch 49 | loss: 0.31565 |  0:19:12s\n",
      "epoch 50 | loss: 0.32475 |  0:19:35s\n",
      "epoch 51 | loss: 0.32692 |  0:20:00s\n",
      "epoch 52 | loss: 0.32314 |  0:20:21s\n",
      "epoch 53 | loss: 0.31824 |  0:20:44s\n",
      "epoch 54 | loss: 0.3168  |  0:21:06s\n",
      "epoch 55 | loss: 0.3186  |  0:21:29s\n",
      "epoch 56 | loss: 0.3175  |  0:21:51s\n",
      "epoch 57 | loss: 0.32138 |  0:22:14s\n",
      "epoch 58 | loss: 0.31531 |  0:22:37s\n",
      "epoch 59 | loss: 0.32162 |  0:22:59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.88531 |  0:00:22s\n",
      "epoch 1  | loss: 0.45036 |  0:00:46s\n",
      "epoch 2  | loss: 0.38011 |  0:01:11s\n",
      "epoch 3  | loss: 0.37047 |  0:01:34s\n",
      "epoch 4  | loss: 0.36544 |  0:01:56s\n",
      "epoch 5  | loss: 0.35333 |  0:02:18s\n",
      "epoch 6  | loss: 0.34735 |  0:02:40s\n",
      "epoch 7  | loss: 0.34333 |  0:03:04s\n",
      "epoch 8  | loss: 0.33326 |  0:03:26s\n",
      "epoch 9  | loss: 0.33396 |  0:03:48s\n",
      "epoch 10 | loss: 0.3291  |  0:04:10s\n",
      "epoch 11 | loss: 0.33335 |  0:04:33s\n",
      "epoch 12 | loss: 0.33609 |  0:04:56s\n",
      "epoch 13 | loss: 0.3272  |  0:05:22s\n",
      "epoch 14 | loss: 0.32744 |  0:05:46s\n",
      "epoch 15 | loss: 0.32778 |  0:06:08s\n",
      "epoch 16 | loss: 0.33217 |  0:06:31s\n",
      "epoch 17 | loss: 0.33119 |  0:06:55s\n",
      "epoch 18 | loss: 0.32972 |  0:07:19s\n",
      "epoch 19 | loss: 0.32382 |  0:07:44s\n",
      "epoch 20 | loss: 0.32044 |  0:08:07s\n",
      "epoch 21 | loss: 0.32228 |  0:08:31s\n",
      "epoch 22 | loss: 0.32318 |  0:08:53s\n",
      "epoch 23 | loss: 0.31931 |  0:09:17s\n",
      "epoch 24 | loss: 0.31832 |  0:09:43s\n",
      "epoch 25 | loss: 0.32146 |  0:10:08s\n",
      "epoch 26 | loss: 0.31939 |  0:10:31s\n",
      "epoch 27 | loss: 0.32324 |  0:10:54s\n",
      "epoch 28 | loss: 0.32076 |  0:11:16s\n",
      "epoch 29 | loss: 0.31843 |  0:11:41s\n",
      "epoch 30 | loss: 0.32007 |  0:12:03s\n",
      "epoch 31 | loss: 0.31646 |  0:12:26s\n",
      "epoch 32 | loss: 0.31788 |  0:12:49s\n",
      "epoch 33 | loss: 0.32226 |  0:13:11s\n",
      "epoch 34 | loss: 0.32327 |  0:13:36s\n",
      "epoch 35 | loss: 0.31879 |  0:14:00s\n",
      "epoch 36 | loss: 0.32053 |  0:14:22s\n",
      "epoch 37 | loss: 0.31749 |  0:14:44s\n",
      "epoch 38 | loss: 0.31663 |  0:15:06s\n",
      "epoch 39 | loss: 0.31701 |  0:15:29s\n",
      "epoch 40 | loss: 0.31846 |  0:15:54s\n",
      "epoch 41 | loss: 0.31558 |  0:16:17s\n",
      "epoch 42 | loss: 0.31806 |  0:16:39s\n",
      "epoch 43 | loss: 0.3132  |  0:17:01s\n",
      "epoch 44 | loss: 0.31541 |  0:17:24s\n",
      "epoch 45 | loss: 0.31546 |  0:17:46s\n",
      "epoch 46 | loss: 0.31311 |  0:18:12s\n",
      "epoch 47 | loss: 0.31327 |  0:18:35s\n",
      "epoch 48 | loss: 0.3125  |  0:18:59s\n",
      "epoch 49 | loss: 0.31129 |  0:19:23s\n",
      "epoch 50 | loss: 0.31289 |  0:19:46s\n",
      "epoch 51 | loss: 0.31092 |  0:20:12s\n",
      "epoch 52 | loss: 0.31229 |  0:20:36s\n",
      "epoch 53 | loss: 0.31126 |  0:20:58s\n",
      "epoch 54 | loss: 0.309   |  0:21:20s\n",
      "epoch 55 | loss: 0.31072 |  0:21:42s\n",
      "epoch 56 | loss: 0.31349 |  0:22:05s\n",
      "epoch 57 | loss: 0.3108  |  0:22:29s\n",
      "epoch 58 | loss: 0.31376 |  0:22:51s\n",
      "epoch 59 | loss: 0.32204 |  0:23:14s\n"
     ]
    }
   ],
   "source": [
    "top10_results = []\n",
    "for model, feats in top10_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([column_names[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top10_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top10_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top10_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top10_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_scores = pd.DataFrame(top10_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.856704</td>\n",
       "      <td>0.909560</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.913265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.911028</td>\n",
       "      <td>0.869396</td>\n",
       "      <td>0.916778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.826612</td>\n",
       "      <td>0.851441</td>\n",
       "      <td>0.835619</td>\n",
       "      <td>0.867916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.856704  0.909560  0.857318  0.913265\n",
       "tabnet    0.859570  0.911028  0.869396  0.916778\n",
       "xgboost   0.826612  0.851441  0.835619  0.867916"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
