{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pickle\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "from bo_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tuned = {\n",
    "    \"learning_rate\" : 0.12084853580348885, \n",
    "    \"max_depth\" : 14, \n",
    "    \"n_estimators\" : 630\n",
    "}\n",
    "# lgbm_tuned += LIGHTGBM_PARAMS\n",
    "\n",
    "xgb_tuned = {\n",
    "    \"learning_rate\" : 0.6407388649081306, \n",
    "    \"max_depth\" : 11, \n",
    "    \"n_estimators\" : 145\n",
    "}\n",
    "# xgb_tuned += XGBOOST_PARAMS\n",
    "\n",
    "tabnet_tuned = {\n",
    "    \"gamma\" : 1.8294789242800777, \n",
    "    \"lambda_sparse\" : 0.024825767831183742, \n",
    "    \"n_steps\" : 3,\n",
    "    \"n_a\" : 8,\n",
    "    \"momentum\" : 0.7,\n",
    "}\n",
    "tabnet_tuned[\"n_d\"] = tabnet_tuned[\"n_a\"]\n",
    "\n",
    "tabnet_paper = {\n",
    "    \"gamma\" : 2.0, \n",
    "    \"lambda_sparse\" : 0.02, \n",
    "    \"n_steps\" : 4,\n",
    "    \"n_a\" : 16,\n",
    "    \"momentum\" : 0.7,\n",
    "}\n",
    "tabnet_paper[\"n_d\"] = tabnet_paper[\"n_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/synthetic/syn1/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/synthetic/syn1/train.csv\")\n",
    "valid = pd.read_csv(\"data/synthetic/syn1/val.csv\")\n",
    "test = pd.read_csv(\"data/synthetic/syn1/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.378190</td>\n",
       "      <td>-0.519822</td>\n",
       "      <td>-0.684763</td>\n",
       "      <td>-0.872423</td>\n",
       "      <td>-0.287110</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>-0.019158</td>\n",
       "      <td>0.590748</td>\n",
       "      <td>-1.590431</td>\n",
       "      <td>1.397031</td>\n",
       "      <td>-0.217588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947871</td>\n",
       "      <td>1.375380</td>\n",
       "      <td>0.029698</td>\n",
       "      <td>0.878627</td>\n",
       "      <td>-0.503844</td>\n",
       "      <td>0.126427</td>\n",
       "      <td>-1.870507</td>\n",
       "      <td>2.310019</td>\n",
       "      <td>-0.893806</td>\n",
       "      <td>0.309268</td>\n",
       "      <td>-0.295812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562566</td>\n",
       "      <td>-0.830877</td>\n",
       "      <td>-1.221890</td>\n",
       "      <td>0.771949</td>\n",
       "      <td>1.679321</td>\n",
       "      <td>0.641072</td>\n",
       "      <td>0.555235</td>\n",
       "      <td>-0.686686</td>\n",
       "      <td>-2.368597</td>\n",
       "      <td>-0.592868</td>\n",
       "      <td>-1.276099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.821857</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>1.211896</td>\n",
       "      <td>-1.201632</td>\n",
       "      <td>0.480880</td>\n",
       "      <td>-0.428486</td>\n",
       "      <td>0.208926</td>\n",
       "      <td>0.870519</td>\n",
       "      <td>-0.359252</td>\n",
       "      <td>1.002516</td>\n",
       "      <td>-1.386892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.523063</td>\n",
       "      <td>1.601884</td>\n",
       "      <td>-1.205119</td>\n",
       "      <td>1.089710</td>\n",
       "      <td>0.799366</td>\n",
       "      <td>0.098410</td>\n",
       "      <td>0.544890</td>\n",
       "      <td>-1.218202</td>\n",
       "      <td>0.212283</td>\n",
       "      <td>-0.053319</td>\n",
       "      <td>-0.835629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0  1.378190 -0.519822 -0.684763 -0.872423 -0.287110  0.096775 -0.019158   \n",
       "1  0.947871  1.375380  0.029698  0.878627 -0.503844  0.126427 -1.870507   \n",
       "2  0.562566 -0.830877 -1.221890  0.771949  1.679321  0.641072  0.555235   \n",
       "3 -0.821857  0.011692  1.211896 -1.201632  0.480880 -0.428486  0.208926   \n",
       "4  1.523063  1.601884 -1.205119  1.089710  0.799366  0.098410  0.544890   \n",
       "\n",
       "         X7        X8        X9       X10  TARGET  \n",
       "0  0.590748 -1.590431  1.397031 -0.217588       0  \n",
       "1  2.310019 -0.893806  0.309268 -0.295812       1  \n",
       "2 -0.686686 -2.368597 -0.592868 -1.276099       0  \n",
       "3  0.870519 -0.359252  1.002516 -1.386892       0  \n",
       "4 -1.218202  0.212283 -0.053319 -0.835629       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop([\"TARGET\"], axis=1)\n",
    "train_y = train[\"TARGET\"]\n",
    "\n",
    "test_X = test.drop([\"TARGET\"], axis=1)\n",
    "test_y = test[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.12084853580348885, max_depth=14, metric='auc',\n",
       "               n_estimators=630, objective='binary', random_state=42)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier(**{**lgbm_tuned, **LIGHTGBM_PARAMS})\n",
    "model_lgbm.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:33] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:22:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.6407388649081306, max_delta_step=0, max_depth=11,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=145, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "model_xgb.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABNET_PARAMS[\"verbose\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.7913  |  0:00:00s\n",
      "epoch 1  | loss: 0.63592 |  0:00:01s\n",
      "epoch 2  | loss: 0.54921 |  0:00:01s\n",
      "epoch 3  | loss: 0.46529 |  0:00:01s\n",
      "epoch 4  | loss: 0.37198 |  0:00:02s\n",
      "epoch 5  | loss: 0.3041  |  0:00:02s\n",
      "epoch 6  | loss: 0.24588 |  0:00:03s\n",
      "epoch 7  | loss: 0.21104 |  0:00:03s\n",
      "epoch 8  | loss: 0.17958 |  0:00:04s\n",
      "epoch 9  | loss: 0.18111 |  0:00:04s\n",
      "epoch 10 | loss: 0.1557  |  0:00:05s\n",
      "epoch 11 | loss: 0.13288 |  0:00:05s\n",
      "epoch 12 | loss: 0.13428 |  0:00:06s\n",
      "epoch 13 | loss: 0.13168 |  0:00:06s\n",
      "epoch 14 | loss: 0.1386  |  0:00:07s\n",
      "epoch 15 | loss: 0.12856 |  0:00:07s\n",
      "epoch 16 | loss: 0.12804 |  0:00:08s\n",
      "epoch 17 | loss: 0.13966 |  0:00:08s\n",
      "epoch 18 | loss: 0.12252 |  0:00:09s\n",
      "epoch 19 | loss: 0.12951 |  0:00:09s\n",
      "epoch 20 | loss: 0.11893 |  0:00:10s\n",
      "epoch 21 | loss: 0.11776 |  0:00:10s\n",
      "epoch 22 | loss: 0.10932 |  0:00:11s\n",
      "epoch 23 | loss: 0.13334 |  0:00:11s\n",
      "epoch 24 | loss: 0.10277 |  0:00:12s\n",
      "epoch 25 | loss: 0.14497 |  0:00:12s\n",
      "epoch 26 | loss: 0.12097 |  0:00:13s\n",
      "epoch 27 | loss: 0.11722 |  0:00:13s\n",
      "epoch 28 | loss: 0.1103  |  0:00:14s\n",
      "epoch 29 | loss: 0.12545 |  0:00:14s\n",
      "epoch 30 | loss: 0.11543 |  0:00:15s\n",
      "epoch 31 | loss: 0.09776 |  0:00:15s\n",
      "epoch 32 | loss: 0.11889 |  0:00:16s\n",
      "epoch 33 | loss: 0.09181 |  0:00:16s\n",
      "epoch 34 | loss: 0.09588 |  0:00:17s\n",
      "epoch 35 | loss: 0.09782 |  0:00:17s\n",
      "epoch 36 | loss: 0.08145 |  0:00:18s\n",
      "epoch 37 | loss: 0.09251 |  0:00:18s\n",
      "epoch 38 | loss: 0.08885 |  0:00:19s\n",
      "epoch 39 | loss: 0.09179 |  0:00:19s\n",
      "epoch 40 | loss: 0.08616 |  0:00:20s\n",
      "epoch 41 | loss: 0.08126 |  0:00:20s\n",
      "epoch 42 | loss: 0.10972 |  0:00:21s\n",
      "epoch 43 | loss: 0.10761 |  0:00:21s\n",
      "epoch 44 | loss: 0.08611 |  0:00:22s\n",
      "epoch 45 | loss: 0.10088 |  0:00:22s\n",
      "epoch 46 | loss: 0.10489 |  0:00:23s\n",
      "epoch 47 | loss: 0.09632 |  0:00:23s\n",
      "epoch 48 | loss: 0.08213 |  0:00:24s\n",
      "epoch 49 | loss: 0.09488 |  0:00:24s\n",
      "epoch 50 | loss: 0.08745 |  0:00:25s\n",
      "epoch 51 | loss: 0.09191 |  0:00:25s\n",
      "epoch 52 | loss: 0.07524 |  0:00:26s\n",
      "epoch 53 | loss: 0.06878 |  0:00:26s\n",
      "epoch 54 | loss: 0.07549 |  0:00:27s\n",
      "epoch 55 | loss: 0.08186 |  0:00:27s\n",
      "epoch 56 | loss: 0.07677 |  0:00:28s\n",
      "epoch 57 | loss: 0.07083 |  0:00:28s\n",
      "epoch 58 | loss: 0.07164 |  0:00:29s\n",
      "epoch 59 | loss: 0.07557 |  0:00:29s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS})\n",
    "model_tabnet.fit(train_X.values, train_y.values, max_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.94416 |  0:00:00s\n",
      "epoch 1  | loss: 0.77382 |  0:00:01s\n",
      "epoch 2  | loss: 0.73031 |  0:00:02s\n",
      "epoch 3  | loss: 0.71069 |  0:00:02s\n",
      "epoch 4  | loss: 0.69902 |  0:00:03s\n",
      "epoch 5  | loss: 0.69593 |  0:00:04s\n",
      "epoch 6  | loss: 0.68483 |  0:00:04s\n",
      "epoch 7  | loss: 0.67384 |  0:00:05s\n",
      "epoch 8  | loss: 0.66438 |  0:00:06s\n",
      "epoch 9  | loss: 0.64986 |  0:00:06s\n",
      "epoch 10 | loss: 0.62519 |  0:00:07s\n",
      "epoch 11 | loss: 0.60379 |  0:00:08s\n",
      "epoch 12 | loss: 0.59164 |  0:00:09s\n",
      "epoch 13 | loss: 0.56938 |  0:00:09s\n",
      "epoch 14 | loss: 0.55585 |  0:00:10s\n",
      "epoch 15 | loss: 0.53979 |  0:00:11s\n",
      "epoch 16 | loss: 0.52304 |  0:00:11s\n",
      "epoch 17 | loss: 0.50177 |  0:00:12s\n",
      "epoch 18 | loss: 0.46382 |  0:00:13s\n",
      "epoch 19 | loss: 0.44076 |  0:00:13s\n",
      "epoch 20 | loss: 0.4033  |  0:00:14s\n",
      "epoch 21 | loss: 0.36189 |  0:00:15s\n",
      "epoch 22 | loss: 0.3464  |  0:00:15s\n",
      "epoch 23 | loss: 0.29322 |  0:00:16s\n",
      "epoch 24 | loss: 0.27512 |  0:00:17s\n",
      "epoch 25 | loss: 0.25088 |  0:00:18s\n",
      "epoch 26 | loss: 0.24114 |  0:00:18s\n",
      "epoch 27 | loss: 0.22366 |  0:00:19s\n",
      "epoch 28 | loss: 0.20957 |  0:00:20s\n",
      "epoch 29 | loss: 0.20543 |  0:00:20s\n",
      "epoch 30 | loss: 0.21598 |  0:00:21s\n",
      "epoch 31 | loss: 0.19902 |  0:00:22s\n",
      "epoch 32 | loss: 0.19521 |  0:00:22s\n",
      "epoch 33 | loss: 0.19018 |  0:00:23s\n",
      "epoch 34 | loss: 0.15675 |  0:00:24s\n",
      "epoch 35 | loss: 0.1608  |  0:00:24s\n",
      "epoch 36 | loss: 0.15238 |  0:00:25s\n",
      "epoch 37 | loss: 0.15762 |  0:00:26s\n",
      "epoch 38 | loss: 0.15347 |  0:00:27s\n",
      "epoch 39 | loss: 0.1468  |  0:00:27s\n",
      "epoch 40 | loss: 0.14629 |  0:00:28s\n",
      "epoch 41 | loss: 0.14424 |  0:00:29s\n",
      "epoch 42 | loss: 0.12935 |  0:00:29s\n",
      "epoch 43 | loss: 0.14225 |  0:00:30s\n",
      "epoch 44 | loss: 0.13491 |  0:00:31s\n",
      "epoch 45 | loss: 0.13823 |  0:00:31s\n",
      "epoch 46 | loss: 0.12852 |  0:00:32s\n",
      "epoch 47 | loss: 0.1244  |  0:00:33s\n",
      "epoch 48 | loss: 0.12671 |  0:00:33s\n",
      "epoch 49 | loss: 0.12576 |  0:00:34s\n",
      "epoch 50 | loss: 0.12445 |  0:00:35s\n",
      "epoch 51 | loss: 0.1322  |  0:00:35s\n",
      "epoch 52 | loss: 0.10493 |  0:00:36s\n",
      "epoch 53 | loss: 0.1119  |  0:00:37s\n",
      "epoch 54 | loss: 0.10829 |  0:00:38s\n",
      "epoch 55 | loss: 0.10794 |  0:00:38s\n",
      "epoch 56 | loss: 0.09207 |  0:00:39s\n",
      "epoch 57 | loss: 0.11537 |  0:00:40s\n",
      "epoch 58 | loss: 0.10349 |  0:00:40s\n",
      "epoch 59 | loss: 0.12189 |  0:00:41s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet_paper = TabNetClassifier(**{**tabnet_paper, **TABNET_PARAMS})\n",
    "model_tabnet_paper.fit(train_X.values, train_y.values, max_epochs=60, batch_size=3000, virtual_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet, f)\n",
    "with open('model_tabnet_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet_paper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'rb') as f:\n",
    "    model_tabnet = pickle.load(f)\n",
    "with open('model_tabnet_paper.pickle', 'rb') as f:\n",
    "    model_tabnet_paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM auc:  1.0\n",
      "XGBoost auc:  1.0\n",
      "TabNet auc:  0.999808\n",
      "TabNet Paper auc:  0.997785\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM auc: \", round(roc_auc_score(test_y, model_lgbm.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"XGBoost auc: \", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"TabNet auc: \", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X.values)[:, 1]), 6))\n",
    "print(\"TabNet Paper auc: \", round(roc_auc_score(test_y, model_tabnet_paper.predict_proba(test_X.values)[:, 1]), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM acc:  1.0\n",
      "XGBoost acc:  1.0\n",
      "TabNet acc:  0.992005\n",
      "TabNet Paper acc:  0.97002\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM acc: \", round(accuracy_score(test_y, model_lgbm.predict(test_X)), 6))\n",
    "print(\"XGBoost acc: \", round(accuracy_score(test_y, model_xgb.predict(test_X)), 6))\n",
    "print(\"TabNet acc: \", round(accuracy_score(test_y, model_tabnet.predict(test_X.values)), 6))\n",
    "print(\"TabNet Paper acc: \", round(accuracy_score(test_y, model_tabnet_paper.predict(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM log_loss:  0.0\n",
      "XGBoost log_loss:  0.00065\n",
      "TabNet log_loss:  0.03235\n",
      "TabNet Paper log_loss:  0.068018\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM log_loss: \", round(log_loss(test_y, model_lgbm.predict_proba(test_X)), 6))\n",
    "print(\"XGBoost log_loss: \", round(log_loss(test_y, model_xgb.predict_proba(test_X)), 6))\n",
    "print(\"TabNet log_loss: \", round(log_loss(test_y, model_tabnet.predict_proba(test_X.values)), 6))\n",
    "print(\"TabNet Paper log_loss: \", round(log_loss(test_y, model_tabnet_paper.predict_proba(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2468,  327, 3060,  497,  969,  232,  911,  220,   78,  206,  970,\n",
       "        787, 1575,  453], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03652314, 0.02215287, 0.01783302, 0.01717239, 0.12828383,\n",
       "       0.10453314, 0.03037683, 0.33732754, 0.02034082, 0.03909687,\n",
       "       0.13433015, 0.06816406, 0.03022396, 0.01364144], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14039684, 0.03198697, 0.02561015, 0.05409149, 0.12356052,\n",
       "       0.00399008, 0.12925596, 0.16550778, 0.02876345, 0.04100787,\n",
       "       0.08514628, 0.0299493 , 0.12511469, 0.01561862])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tabnet.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = list(enumerate(model_lgbm.feature_importances_))\n",
    "importance_xgb = model_xgb.get_booster().get_score(importance_type='weight').items()\n",
    "importance_tabnet = list(enumerate(model_tabnet.feature_importances_))\n",
    "importance_tabnet_paper = list(enumerate(model_tabnet_paper.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = sorted(importance_lgbm, key=lambda x: x[1], reverse=True)\n",
    "importance_xgb = sorted(importance_xgb, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet = sorted(importance_tabnet, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet_paper = sorted(importance_tabnet_paper, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x424.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = shap.TreeExplainer(model_xgb).shap_values(train_X)\n",
    "shap.summary_plot(shap_values, train_X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame([train.columns[x[0]] for x in importance_lgbm], columns=[\"LightGBM\"])\n",
    "df_compare[\"XGBoost\"] = [x[0] for x in importance_xgb]\n",
    "df_compare[\"SHAP_XGBoost\"] = train_X.columns[np.argsort(np.abs(shap_values).mean(0))][::-1]\n",
    "df_compare[\"TabNet\"] = [train.columns[x[0]] for x in importance_tabnet]\n",
    "df_compare[\"TabNet_Paper\"] = [train.columns[x[0]] for x in importance_tabnet_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X0</td>\n",
       "      <td>X1</td>\n",
       "      <td>X1</td>\n",
       "      <td>X1</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X6</td>\n",
       "      <td>X10</td>\n",
       "      <td>X2</td>\n",
       "      <td>X5</td>\n",
       "      <td>X4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X1</td>\n",
       "      <td>X2</td>\n",
       "      <td>X3</td>\n",
       "      <td>X7</td>\n",
       "      <td>X5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X2</td>\n",
       "      <td>X5</td>\n",
       "      <td>X4</td>\n",
       "      <td>X4</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X3</td>\n",
       "      <td>X9</td>\n",
       "      <td>X9</td>\n",
       "      <td>X9</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X7</td>\n",
       "      <td>X7</td>\n",
       "      <td>X5</td>\n",
       "      <td>X3</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X4</td>\n",
       "      <td>X3</td>\n",
       "      <td>X10</td>\n",
       "      <td>X6</td>\n",
       "      <td>X7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X8</td>\n",
       "      <td>X4</td>\n",
       "      <td>X8</td>\n",
       "      <td>X2</td>\n",
       "      <td>X8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X9</td>\n",
       "      <td>X8</td>\n",
       "      <td>X7</td>\n",
       "      <td>X8</td>\n",
       "      <td>X6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X10</td>\n",
       "      <td>X6</td>\n",
       "      <td>X6</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM XGBoost SHAP_XGBoost TabNet TabNet_Paper\n",
       "0        X5      X0           X0     X0           X0\n",
       "1        X0      X1           X1     X1           X1\n",
       "2        X6     X10           X2     X5           X4\n",
       "3        X1      X2           X3     X7           X5\n",
       "4        X2      X5           X4     X4           X9\n",
       "5        X3      X9           X9     X9           X3\n",
       "6        X7      X7           X5     X3           X2\n",
       "7        X4      X3          X10     X6           X7\n",
       "8        X8      X4           X8     X2           X8\n",
       "9        X9      X8           X7     X8           X6\n",
       "10      X10      X6           X6    X10          X10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:2, col1]) & set(df_compare.loc[:2, col2])))\n",
    "        top_3.append(d)\n",
    "top_3_data = pd.DataFrame(top_3, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             3             1       2             1        1\n",
       "SHAP_XGBoost         1             3       2             2        2\n",
       "TabNet               2             2       3             2        2\n",
       "TabNet_Paper         1             2       2             3        2\n",
       "XGBoost              1             2       2             2        3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 3 признака из каждой и обучить бустинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:4, col1]) & set(df_compare.loc[:4, col2])))\n",
    "        top_5.append(d)\n",
    "top_5_data = pd.DataFrame(top_5, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             5             3       3             3        4\n",
       "SHAP_XGBoost         3             5       3             3        3\n",
       "TabNet               3             3       5             4        3\n",
       "TabNet_Paper         3             3       4             5        3\n",
       "XGBoost              4             3       3             3        5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_5_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:9, col1]) & set(df_compare.loc[:9, col2])))\n",
    "        top_10.append(d)\n",
    "top_10_data = pd.DataFrame(top_10, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM            10             9      10            10        9\n",
       "SHAP_XGBoost         9            10       9             9       10\n",
       "TabNet              10             9      10            10        9\n",
       "TabNet_Paper        10             9      10            10        9\n",
       "XGBoost              9            10       9             9       10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_feats = {}\n",
    "top3_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\"]\n",
    "top3_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\"]\n",
    "top3_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_feats = {}\n",
    "top10_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\", \"occupation\", \"education_num\", \"capital_gain\", \"education\", \"workclass\", \"capital_loss\", \"native_country\"]\n",
    "top10_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\", \"relationship\", \"education_num\", \"occupation\", \"fnlwgt\", \"hours_per_week\", \"sex\", \"capital_loss\"]\n",
    "top10_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\", \"hours_per_week\", \"education_num\", \"capital_gain\", \"education\", \"sex\", \"workclass\", \"capital_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top3_results = []\n",
    "for model, feats in top3_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([train.columns[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top3_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top3_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top3_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top3_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_scores = pd.DataFrame(top3_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.805527</td>\n",
       "      <td>0.851631</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.864625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.824770</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.857539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.769089</td>\n",
       "      <td>0.751890</td>\n",
       "      <td>0.760491</td>\n",
       "      <td>0.727796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.805527  0.851631  0.819652  0.864625\n",
       "tabnet    0.824770  0.864272  0.819652  0.857539\n",
       "xgboost   0.769089  0.751890  0.760491  0.727796"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.79592 |  0:00:12s\n",
      "epoch 1  | loss: 0.49582 |  0:00:25s\n",
      "epoch 2  | loss: 0.44158 |  0:00:40s\n",
      "epoch 3  | loss: 0.40275 |  0:00:53s\n",
      "epoch 4  | loss: 0.40626 |  0:01:05s\n",
      "epoch 5  | loss: 0.4009  |  0:01:18s\n",
      "epoch 6  | loss: 0.39774 |  0:01:30s\n",
      "epoch 7  | loss: 0.39294 |  0:01:43s\n",
      "epoch 8  | loss: 0.3906  |  0:01:57s\n",
      "epoch 9  | loss: 0.39566 |  0:02:17s\n",
      "epoch 10 | loss: 0.3941  |  0:02:54s\n",
      "epoch 11 | loss: 0.39292 |  0:03:31s\n",
      "epoch 12 | loss: 0.39145 |  0:04:11s\n",
      "epoch 13 | loss: 0.3886  |  0:04:34s\n",
      "epoch 14 | loss: 0.39061 |  0:05:00s\n",
      "epoch 15 | loss: 0.39403 |  0:05:23s\n",
      "epoch 16 | loss: 0.38763 |  0:05:47s\n",
      "epoch 17 | loss: 0.38817 |  0:06:08s\n",
      "epoch 18 | loss: 0.39708 |  0:06:32s\n",
      "epoch 19 | loss: 0.39374 |  0:06:56s\n",
      "epoch 20 | loss: 0.3895  |  0:07:21s\n",
      "epoch 21 | loss: 0.38912 |  0:07:45s\n",
      "epoch 22 | loss: 0.38642 |  0:08:08s\n",
      "epoch 23 | loss: 0.3847  |  0:08:33s\n",
      "epoch 24 | loss: 0.38419 |  0:08:57s\n",
      "epoch 25 | loss: 0.38397 |  0:09:20s\n",
      "epoch 26 | loss: 0.38094 |  0:09:44s\n",
      "epoch 27 | loss: 0.38124 |  0:10:07s\n",
      "epoch 28 | loss: 0.38337 |  0:10:31s\n",
      "epoch 29 | loss: 0.38498 |  0:10:55s\n",
      "epoch 30 | loss: 0.38105 |  0:11:19s\n",
      "epoch 31 | loss: 0.38232 |  0:11:40s\n",
      "epoch 32 | loss: 0.3815  |  0:12:04s\n",
      "epoch 33 | loss: 0.38328 |  0:12:26s\n",
      "epoch 34 | loss: 0.37821 |  0:12:49s\n",
      "epoch 35 | loss: 0.3803  |  0:13:13s\n",
      "epoch 36 | loss: 0.37915 |  0:13:36s\n",
      "epoch 37 | loss: 0.37989 |  0:13:59s\n",
      "epoch 38 | loss: 0.39247 |  0:14:23s\n",
      "epoch 39 | loss: 0.3804  |  0:14:46s\n",
      "epoch 40 | loss: 0.37794 |  0:15:11s\n",
      "epoch 41 | loss: 0.37671 |  0:15:32s\n",
      "epoch 42 | loss: 0.37527 |  0:15:54s\n",
      "epoch 43 | loss: 0.37477 |  0:16:15s\n",
      "epoch 44 | loss: 0.38458 |  0:16:38s\n",
      "epoch 45 | loss: 0.38768 |  0:17:00s\n",
      "epoch 46 | loss: 0.37762 |  0:17:25s\n",
      "epoch 47 | loss: 0.37628 |  0:17:48s\n",
      "epoch 48 | loss: 0.37779 |  0:18:10s\n",
      "epoch 49 | loss: 0.37808 |  0:18:33s\n",
      "epoch 50 | loss: 0.37675 |  0:18:56s\n",
      "epoch 51 | loss: 0.37481 |  0:19:20s\n",
      "epoch 52 | loss: 0.37458 |  0:19:43s\n",
      "epoch 53 | loss: 0.37851 |  0:20:06s\n",
      "epoch 54 | loss: 0.37758 |  0:20:30s\n",
      "epoch 55 | loss: 0.38001 |  0:20:51s\n",
      "epoch 56 | loss: 0.38308 |  0:21:15s\n",
      "epoch 57 | loss: 0.38137 |  0:21:39s\n",
      "epoch 58 | loss: 0.37925 |  0:22:01s\n",
      "epoch 59 | loss: 0.38585 |  0:22:24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:08] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:42:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.90432 |  0:00:23s\n",
      "epoch 1  | loss: 0.39276 |  0:00:49s\n",
      "epoch 2  | loss: 0.34943 |  0:01:11s\n",
      "epoch 3  | loss: 0.34461 |  0:01:34s\n",
      "epoch 4  | loss: 0.34024 |  0:01:57s\n",
      "epoch 5  | loss: 0.34186 |  0:02:20s\n",
      "epoch 6  | loss: 0.34383 |  0:02:42s\n",
      "epoch 7  | loss: 0.33729 |  0:03:08s\n",
      "epoch 8  | loss: 0.33883 |  0:03:30s\n",
      "epoch 9  | loss: 0.33975 |  0:03:54s\n",
      "epoch 10 | loss: 0.34485 |  0:04:17s\n",
      "epoch 11 | loss: 0.33227 |  0:04:40s\n",
      "epoch 12 | loss: 0.33144 |  0:05:06s\n",
      "epoch 13 | loss: 0.3314  |  0:05:29s\n",
      "epoch 14 | loss: 0.33928 |  0:05:50s\n",
      "epoch 15 | loss: 0.32989 |  0:06:12s\n",
      "epoch 16 | loss: 0.33309 |  0:06:33s\n",
      "epoch 17 | loss: 0.33441 |  0:06:56s\n",
      "epoch 18 | loss: 0.33631 |  0:07:21s\n",
      "epoch 19 | loss: 0.32965 |  0:07:44s\n",
      "epoch 20 | loss: 0.33031 |  0:08:08s\n",
      "epoch 21 | loss: 0.32679 |  0:08:31s\n",
      "epoch 22 | loss: 0.32387 |  0:08:53s\n",
      "epoch 23 | loss: 0.32129 |  0:09:18s\n",
      "epoch 24 | loss: 0.3256  |  0:09:40s\n",
      "epoch 25 | loss: 0.33124 |  0:10:03s\n",
      "epoch 26 | loss: 0.32599 |  0:10:26s\n",
      "epoch 27 | loss: 0.32683 |  0:10:49s\n",
      "epoch 28 | loss: 0.32928 |  0:11:12s\n",
      "epoch 29 | loss: 0.32668 |  0:11:35s\n",
      "epoch 30 | loss: 0.32345 |  0:11:58s\n",
      "epoch 31 | loss: 0.32416 |  0:12:21s\n",
      "epoch 32 | loss: 0.32507 |  0:12:43s\n",
      "epoch 33 | loss: 0.32404 |  0:13:05s\n",
      "epoch 34 | loss: 0.32054 |  0:13:29s\n",
      "epoch 35 | loss: 0.32212 |  0:13:53s\n",
      "epoch 36 | loss: 0.32217 |  0:14:14s\n",
      "epoch 37 | loss: 0.31913 |  0:14:37s\n",
      "epoch 38 | loss: 0.32162 |  0:15:00s\n",
      "epoch 39 | loss: 0.32277 |  0:15:23s\n",
      "epoch 40 | loss: 0.31707 |  0:15:46s\n",
      "epoch 41 | loss: 0.31975 |  0:16:09s\n",
      "epoch 42 | loss: 0.3171  |  0:16:31s\n",
      "epoch 43 | loss: 0.32048 |  0:16:55s\n",
      "epoch 44 | loss: 0.32208 |  0:17:17s\n",
      "epoch 45 | loss: 0.31896 |  0:17:41s\n",
      "epoch 46 | loss: 0.31771 |  0:18:03s\n",
      "epoch 47 | loss: 0.32248 |  0:18:25s\n",
      "epoch 48 | loss: 0.31958 |  0:18:48s\n",
      "epoch 49 | loss: 0.31565 |  0:19:12s\n",
      "epoch 50 | loss: 0.32475 |  0:19:35s\n",
      "epoch 51 | loss: 0.32692 |  0:20:00s\n",
      "epoch 52 | loss: 0.32314 |  0:20:21s\n",
      "epoch 53 | loss: 0.31824 |  0:20:44s\n",
      "epoch 54 | loss: 0.3168  |  0:21:06s\n",
      "epoch 55 | loss: 0.3186  |  0:21:29s\n",
      "epoch 56 | loss: 0.3175  |  0:21:51s\n",
      "epoch 57 | loss: 0.32138 |  0:22:14s\n",
      "epoch 58 | loss: 0.31531 |  0:22:37s\n",
      "epoch 59 | loss: 0.32162 |  0:22:59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.88531 |  0:00:22s\n",
      "epoch 1  | loss: 0.45036 |  0:00:46s\n",
      "epoch 2  | loss: 0.38011 |  0:01:11s\n",
      "epoch 3  | loss: 0.37047 |  0:01:34s\n",
      "epoch 4  | loss: 0.36544 |  0:01:56s\n",
      "epoch 5  | loss: 0.35333 |  0:02:18s\n",
      "epoch 6  | loss: 0.34735 |  0:02:40s\n",
      "epoch 7  | loss: 0.34333 |  0:03:04s\n",
      "epoch 8  | loss: 0.33326 |  0:03:26s\n",
      "epoch 9  | loss: 0.33396 |  0:03:48s\n",
      "epoch 10 | loss: 0.3291  |  0:04:10s\n",
      "epoch 11 | loss: 0.33335 |  0:04:33s\n",
      "epoch 12 | loss: 0.33609 |  0:04:56s\n",
      "epoch 13 | loss: 0.3272  |  0:05:22s\n",
      "epoch 14 | loss: 0.32744 |  0:05:46s\n",
      "epoch 15 | loss: 0.32778 |  0:06:08s\n",
      "epoch 16 | loss: 0.33217 |  0:06:31s\n",
      "epoch 17 | loss: 0.33119 |  0:06:55s\n",
      "epoch 18 | loss: 0.32972 |  0:07:19s\n",
      "epoch 19 | loss: 0.32382 |  0:07:44s\n",
      "epoch 20 | loss: 0.32044 |  0:08:07s\n",
      "epoch 21 | loss: 0.32228 |  0:08:31s\n",
      "epoch 22 | loss: 0.32318 |  0:08:53s\n",
      "epoch 23 | loss: 0.31931 |  0:09:17s\n",
      "epoch 24 | loss: 0.31832 |  0:09:43s\n",
      "epoch 25 | loss: 0.32146 |  0:10:08s\n",
      "epoch 26 | loss: 0.31939 |  0:10:31s\n",
      "epoch 27 | loss: 0.32324 |  0:10:54s\n",
      "epoch 28 | loss: 0.32076 |  0:11:16s\n",
      "epoch 29 | loss: 0.31843 |  0:11:41s\n",
      "epoch 30 | loss: 0.32007 |  0:12:03s\n",
      "epoch 31 | loss: 0.31646 |  0:12:26s\n",
      "epoch 32 | loss: 0.31788 |  0:12:49s\n",
      "epoch 33 | loss: 0.32226 |  0:13:11s\n",
      "epoch 34 | loss: 0.32327 |  0:13:36s\n",
      "epoch 35 | loss: 0.31879 |  0:14:00s\n",
      "epoch 36 | loss: 0.32053 |  0:14:22s\n",
      "epoch 37 | loss: 0.31749 |  0:14:44s\n",
      "epoch 38 | loss: 0.31663 |  0:15:06s\n",
      "epoch 39 | loss: 0.31701 |  0:15:29s\n",
      "epoch 40 | loss: 0.31846 |  0:15:54s\n",
      "epoch 41 | loss: 0.31558 |  0:16:17s\n",
      "epoch 42 | loss: 0.31806 |  0:16:39s\n",
      "epoch 43 | loss: 0.3132  |  0:17:01s\n",
      "epoch 44 | loss: 0.31541 |  0:17:24s\n",
      "epoch 45 | loss: 0.31546 |  0:17:46s\n",
      "epoch 46 | loss: 0.31311 |  0:18:12s\n",
      "epoch 47 | loss: 0.31327 |  0:18:35s\n",
      "epoch 48 | loss: 0.3125  |  0:18:59s\n",
      "epoch 49 | loss: 0.31129 |  0:19:23s\n",
      "epoch 50 | loss: 0.31289 |  0:19:46s\n",
      "epoch 51 | loss: 0.31092 |  0:20:12s\n",
      "epoch 52 | loss: 0.31229 |  0:20:36s\n",
      "epoch 53 | loss: 0.31126 |  0:20:58s\n",
      "epoch 54 | loss: 0.309   |  0:21:20s\n",
      "epoch 55 | loss: 0.31072 |  0:21:42s\n",
      "epoch 56 | loss: 0.31349 |  0:22:05s\n",
      "epoch 57 | loss: 0.3108  |  0:22:29s\n",
      "epoch 58 | loss: 0.31376 |  0:22:51s\n",
      "epoch 59 | loss: 0.32204 |  0:23:14s\n"
     ]
    }
   ],
   "source": [
    "top10_results = []\n",
    "for model, feats in top10_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([column_names[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top10_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top10_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top10_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top10_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_scores = pd.DataFrame(top10_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.856704</td>\n",
       "      <td>0.909560</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.913265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.911028</td>\n",
       "      <td>0.869396</td>\n",
       "      <td>0.916778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.826612</td>\n",
       "      <td>0.851441</td>\n",
       "      <td>0.835619</td>\n",
       "      <td>0.867916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.856704  0.909560  0.857318  0.913265\n",
       "tabnet    0.859570  0.911028  0.869396  0.916778\n",
       "xgboost   0.826612  0.851441  0.835619  0.867916"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
