{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pickle\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "from bo_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tuned = {\n",
    "    \"learning_rate\" : 0.4540837973031734, \n",
    "    \"max_depth\" : 3, \n",
    "    \"n_estimators\" : 315\n",
    "}\n",
    "# lgbm_tuned += LIGHTGBM_PARAMS\n",
    "\n",
    "xgb_tuned = {\n",
    "    \"learning_rate\" : 0.8880765022899698, \n",
    "    \"max_depth\" : 4, \n",
    "    \"n_estimators\" : 675\n",
    "}\n",
    "# xgb_tuned += XGBOOST_PARAMS\n",
    "\n",
    "tabnet_tuned = {\n",
    "    \"gamma\" : 1.5677018396290885, \n",
    "    \"lambda_sparse\" : 0.04841913603075304, \n",
    "    \"n_steps\" : 4,\n",
    "    \"n_a\" : 32,\n",
    "    \"momentum\" : 0.6,\n",
    "}\n",
    "tabnet_tuned[\"n_d\"] = tabnet_tuned[\"n_a\"]\n",
    "\n",
    "tabnet_paper = {\n",
    "    \"gamma\" : 2.0, \n",
    "    \"lambda_sparse\" : 0.01, \n",
    "    \"n_steps\" : 4,\n",
    "    \"n_a\" : 16,\n",
    "    \"momentum\" : 0.7,\n",
    "}\n",
    "tabnet_paper[\"n_d\"] = tabnet_paper[\"n_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/synthetic/syn3/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/synthetic/syn3/train.csv\")\n",
    "valid = pd.read_csv(\"data/synthetic/syn3/val.csv\")\n",
    "test = pd.read_csv(\"data/synthetic/syn3/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.473626</td>\n",
       "      <td>-1.081220</td>\n",
       "      <td>1.943384</td>\n",
       "      <td>-0.754866</td>\n",
       "      <td>-0.110198</td>\n",
       "      <td>-1.860726</td>\n",
       "      <td>1.482790</td>\n",
       "      <td>-1.100806</td>\n",
       "      <td>-1.048873</td>\n",
       "      <td>-1.860841</td>\n",
       "      <td>-0.094227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.080454</td>\n",
       "      <td>-1.075954</td>\n",
       "      <td>-0.714059</td>\n",
       "      <td>0.258401</td>\n",
       "      <td>0.415359</td>\n",
       "      <td>-0.532207</td>\n",
       "      <td>1.083638</td>\n",
       "      <td>0.567063</td>\n",
       "      <td>-1.580961</td>\n",
       "      <td>-0.840108</td>\n",
       "      <td>-0.955982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491064</td>\n",
       "      <td>1.183288</td>\n",
       "      <td>1.342142</td>\n",
       "      <td>-0.811380</td>\n",
       "      <td>0.468081</td>\n",
       "      <td>0.973829</td>\n",
       "      <td>-1.275652</td>\n",
       "      <td>1.539071</td>\n",
       "      <td>-0.381523</td>\n",
       "      <td>1.805232</td>\n",
       "      <td>-0.440300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140453</td>\n",
       "      <td>0.362619</td>\n",
       "      <td>-0.024560</td>\n",
       "      <td>-0.122030</td>\n",
       "      <td>-0.679300</td>\n",
       "      <td>0.427168</td>\n",
       "      <td>0.238634</td>\n",
       "      <td>-1.373413</td>\n",
       "      <td>-0.572716</td>\n",
       "      <td>0.288809</td>\n",
       "      <td>-0.517400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.631385</td>\n",
       "      <td>-0.249985</td>\n",
       "      <td>0.838493</td>\n",
       "      <td>0.982957</td>\n",
       "      <td>-1.247868</td>\n",
       "      <td>0.461186</td>\n",
       "      <td>-1.415161</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>0.354399</td>\n",
       "      <td>-0.835789</td>\n",
       "      <td>-1.390095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0 -0.473626 -1.081220  1.943384 -0.754866 -0.110198 -1.860726  1.482790   \n",
       "1 -1.080454 -1.075954 -0.714059  0.258401  0.415359 -0.532207  1.083638   \n",
       "2  0.491064  1.183288  1.342142 -0.811380  0.468081  0.973829 -1.275652   \n",
       "3  0.140453  0.362619 -0.024560 -0.122030 -0.679300  0.427168  0.238634   \n",
       "4 -0.631385 -0.249985  0.838493  0.982957 -1.247868  0.461186 -1.415161   \n",
       "\n",
       "         X7        X8        X9       X10  TARGET  \n",
       "0 -1.100806 -1.048873 -1.860841 -0.094227       1  \n",
       "1  0.567063 -1.580961 -0.840108 -0.955982       1  \n",
       "2  1.539071 -0.381523  1.805232 -0.440300       0  \n",
       "3 -1.373413 -0.572716  0.288809 -0.517400       0  \n",
       "4  0.378700  0.354399 -0.835789 -1.390095       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop([\"TARGET\"], axis=1)\n",
    "train_y = train[\"TARGET\"]\n",
    "\n",
    "test_X = test.drop([\"TARGET\"], axis=1)\n",
    "test_y = test[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.4540837973031734, max_depth=3, metric='auc',\n",
       "               n_estimators=315, objective='binary', random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier(**{**lgbm_tuned, **LIGHTGBM_PARAMS})\n",
    "model_lgbm.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:41:45] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.8880765022899698, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=675, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "model_xgb.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABNET_PARAMS[\"verbose\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.71688 |  0:00:01s\n",
      "epoch 1  | loss: 0.23316 |  0:00:02s\n",
      "epoch 2  | loss: 0.13383 |  0:00:02s\n",
      "epoch 3  | loss: 0.11844 |  0:00:03s\n",
      "epoch 4  | loss: 0.11699 |  0:00:04s\n",
      "epoch 5  | loss: 0.1205  |  0:00:05s\n",
      "epoch 6  | loss: 0.10254 |  0:00:06s\n",
      "epoch 7  | loss: 0.09732 |  0:00:07s\n",
      "epoch 8  | loss: 0.09549 |  0:00:08s\n",
      "epoch 9  | loss: 0.09111 |  0:00:09s\n",
      "epoch 10 | loss: 0.08775 |  0:00:10s\n",
      "epoch 11 | loss: 0.0846  |  0:00:11s\n",
      "epoch 12 | loss: 0.10093 |  0:00:12s\n",
      "epoch 13 | loss: 0.08295 |  0:00:13s\n",
      "epoch 14 | loss: 0.08162 |  0:00:14s\n",
      "epoch 15 | loss: 0.0885  |  0:00:15s\n",
      "epoch 16 | loss: 0.07932 |  0:00:16s\n",
      "epoch 17 | loss: 0.07951 |  0:00:17s\n",
      "epoch 18 | loss: 0.0828  |  0:00:18s\n",
      "epoch 19 | loss: 0.07779 |  0:00:19s\n",
      "epoch 20 | loss: 0.07258 |  0:00:20s\n",
      "epoch 21 | loss: 0.0849  |  0:00:21s\n",
      "epoch 22 | loss: 0.06722 |  0:00:22s\n",
      "epoch 23 | loss: 0.0655  |  0:00:23s\n",
      "epoch 24 | loss: 0.0638  |  0:00:24s\n",
      "epoch 25 | loss: 0.07026 |  0:00:25s\n",
      "epoch 26 | loss: 0.08738 |  0:00:26s\n",
      "epoch 27 | loss: 0.08141 |  0:00:27s\n",
      "epoch 28 | loss: 0.06831 |  0:00:28s\n",
      "epoch 29 | loss: 0.0642  |  0:00:29s\n",
      "epoch 30 | loss: 0.07236 |  0:00:30s\n",
      "epoch 31 | loss: 0.07312 |  0:00:31s\n",
      "epoch 32 | loss: 0.0602  |  0:00:32s\n",
      "epoch 33 | loss: 0.05771 |  0:00:33s\n",
      "epoch 34 | loss: 0.05725 |  0:00:34s\n",
      "epoch 35 | loss: 0.0565  |  0:00:35s\n",
      "epoch 36 | loss: 0.05191 |  0:00:36s\n",
      "epoch 37 | loss: 0.06211 |  0:00:37s\n",
      "epoch 38 | loss: 0.05396 |  0:00:38s\n",
      "epoch 39 | loss: 0.06588 |  0:00:39s\n",
      "epoch 40 | loss: 0.05064 |  0:00:40s\n",
      "epoch 41 | loss: 0.05619 |  0:00:41s\n",
      "epoch 42 | loss: 0.05544 |  0:00:42s\n",
      "epoch 43 | loss: 0.06152 |  0:00:43s\n",
      "epoch 44 | loss: 0.08851 |  0:00:43s\n",
      "epoch 45 | loss: 0.0692  |  0:00:44s\n",
      "epoch 46 | loss: 0.06566 |  0:00:45s\n",
      "epoch 47 | loss: 0.06979 |  0:00:46s\n",
      "epoch 48 | loss: 0.06401 |  0:00:47s\n",
      "epoch 49 | loss: 0.05719 |  0:00:48s\n",
      "epoch 50 | loss: 0.06025 |  0:00:49s\n",
      "epoch 51 | loss: 0.0557  |  0:00:50s\n",
      "epoch 52 | loss: 0.04914 |  0:00:51s\n",
      "epoch 53 | loss: 0.05253 |  0:00:52s\n",
      "epoch 54 | loss: 0.04971 |  0:00:53s\n",
      "epoch 55 | loss: 0.05443 |  0:00:54s\n",
      "epoch 56 | loss: 0.05129 |  0:00:55s\n",
      "epoch 57 | loss: 0.05095 |  0:00:56s\n",
      "epoch 58 | loss: 0.04349 |  0:00:57s\n",
      "epoch 59 | loss: 0.05401 |  0:00:58s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS})\n",
    "model_tabnet.fit(train_X.values, train_y.values, max_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.88826 |  0:00:00s\n",
      "epoch 1  | loss: 0.55182 |  0:00:01s\n",
      "epoch 2  | loss: 0.36629 |  0:00:02s\n",
      "epoch 3  | loss: 0.26303 |  0:00:02s\n",
      "epoch 4  | loss: 0.19404 |  0:00:03s\n",
      "epoch 5  | loss: 0.15895 |  0:00:04s\n",
      "epoch 6  | loss: 0.12469 |  0:00:04s\n",
      "epoch 7  | loss: 0.11345 |  0:00:05s\n",
      "epoch 8  | loss: 0.10548 |  0:00:06s\n",
      "epoch 9  | loss: 0.10196 |  0:00:07s\n",
      "epoch 10 | loss: 0.09828 |  0:00:07s\n",
      "epoch 11 | loss: 0.09268 |  0:00:08s\n",
      "epoch 12 | loss: 0.08287 |  0:00:09s\n",
      "epoch 13 | loss: 0.09198 |  0:00:09s\n",
      "epoch 14 | loss: 0.08547 |  0:00:10s\n",
      "epoch 15 | loss: 0.08461 |  0:00:11s\n",
      "epoch 16 | loss: 0.08383 |  0:00:11s\n",
      "epoch 17 | loss: 0.07803 |  0:00:12s\n",
      "epoch 18 | loss: 0.08161 |  0:00:13s\n",
      "epoch 19 | loss: 0.07364 |  0:00:14s\n",
      "epoch 20 | loss: 0.07437 |  0:00:14s\n",
      "epoch 21 | loss: 0.07585 |  0:00:15s\n",
      "epoch 22 | loss: 0.0728  |  0:00:16s\n",
      "epoch 23 | loss: 0.07934 |  0:00:16s\n",
      "epoch 24 | loss: 0.0698  |  0:00:17s\n",
      "epoch 25 | loss: 0.07083 |  0:00:18s\n",
      "epoch 26 | loss: 0.06029 |  0:00:18s\n",
      "epoch 27 | loss: 0.07635 |  0:00:19s\n",
      "epoch 28 | loss: 0.07074 |  0:00:20s\n",
      "epoch 29 | loss: 0.06211 |  0:00:20s\n",
      "epoch 30 | loss: 0.0628  |  0:00:21s\n",
      "epoch 31 | loss: 0.0636  |  0:00:22s\n",
      "epoch 32 | loss: 0.06541 |  0:00:23s\n",
      "epoch 33 | loss: 0.06032 |  0:00:23s\n",
      "epoch 34 | loss: 0.06315 |  0:00:24s\n",
      "epoch 35 | loss: 0.05472 |  0:00:25s\n",
      "epoch 36 | loss: 0.06036 |  0:00:25s\n",
      "epoch 37 | loss: 0.06185 |  0:00:26s\n",
      "epoch 38 | loss: 0.05486 |  0:00:27s\n",
      "epoch 39 | loss: 0.0575  |  0:00:27s\n",
      "epoch 40 | loss: 0.05829 |  0:00:28s\n",
      "epoch 41 | loss: 0.0537  |  0:00:29s\n",
      "epoch 42 | loss: 0.0533  |  0:00:30s\n",
      "epoch 43 | loss: 0.058   |  0:00:30s\n",
      "epoch 44 | loss: 0.05678 |  0:00:31s\n",
      "epoch 45 | loss: 0.05598 |  0:00:32s\n",
      "epoch 46 | loss: 0.06    |  0:00:32s\n",
      "epoch 47 | loss: 0.05457 |  0:00:33s\n",
      "epoch 48 | loss: 0.05443 |  0:00:34s\n",
      "epoch 49 | loss: 0.05132 |  0:00:34s\n",
      "epoch 50 | loss: 0.05251 |  0:00:35s\n",
      "epoch 51 | loss: 0.06101 |  0:00:36s\n",
      "epoch 52 | loss: 0.05443 |  0:00:36s\n",
      "epoch 53 | loss: 0.04998 |  0:00:37s\n",
      "epoch 54 | loss: 0.05651 |  0:00:38s\n",
      "epoch 55 | loss: 0.05086 |  0:00:38s\n",
      "epoch 56 | loss: 0.05431 |  0:00:39s\n",
      "epoch 57 | loss: 0.0499  |  0:00:40s\n",
      "epoch 58 | loss: 0.05087 |  0:00:41s\n",
      "epoch 59 | loss: 0.05472 |  0:00:41s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet_paper = TabNetClassifier(**{**tabnet_paper, **TABNET_PARAMS})\n",
    "model_tabnet_paper.fit(train_X.values, train_y.values, max_epochs=60, batch_size=3000, virtual_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet, f)\n",
    "with open('model_tabnet_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet_paper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'rb') as f:\n",
    "    model_tabnet = pickle.load(f)\n",
    "with open('model_tabnet_paper.pickle', 'rb') as f:\n",
    "    model_tabnet_paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM auc:  0.999817\n",
      "XGBoost auc:  0.999693\n",
      "TabNet auc:  0.998949\n",
      "TabNet Paper auc:  0.998755\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM auc: \", round(roc_auc_score(test_y, model_lgbm.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"XGBoost auc: \", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"TabNet auc: \", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X.values)[:, 1]), 6))\n",
    "print(\"TabNet Paper auc: \", round(roc_auc_score(test_y, model_tabnet_paper.predict_proba(test_X.values)[:, 1]), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM acc:  0.992005\n",
      "XGBoost acc:  0.992672\n",
      "TabNet acc:  0.977348\n",
      "TabNet Paper acc:  0.980013\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM acc: \", round(accuracy_score(test_y, model_lgbm.predict(test_X)), 6))\n",
    "print(\"XGBoost acc: \", round(accuracy_score(test_y, model_xgb.predict(test_X)), 6))\n",
    "print(\"TabNet acc: \", round(accuracy_score(test_y, model_tabnet.predict(test_X.values)), 6))\n",
    "print(\"TabNet Paper acc: \", round(accuracy_score(test_y, model_tabnet_paper.predict(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM log_loss:  0.024455\n",
      "XGBoost log_loss:  0.025616\n",
      "TabNet log_loss:  0.049186\n",
      "TabNet Paper log_loss:  0.045577\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM log_loss: \", round(log_loss(test_y, model_lgbm.predict_proba(test_X)), 6))\n",
    "print(\"XGBoost log_loss: \", round(log_loss(test_y, model_xgb.predict_proba(test_X)), 6))\n",
    "print(\"TabNet log_loss: \", round(log_loss(test_y, model_tabnet.predict_proba(test_X.values)), 6))\n",
    "print(\"TabNet Paper log_loss: \", round(log_loss(test_y, model_tabnet_paper.predict_proba(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = list(enumerate(model_lgbm.feature_importances_))\n",
    "importance_xgb = model_xgb.get_booster().get_score(importance_type='weight').items()\n",
    "importance_tabnet = list(enumerate(model_tabnet.feature_importances_))\n",
    "importance_tabnet_paper = list(enumerate(model_tabnet_paper.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = sorted(importance_lgbm, key=lambda x: x[1], reverse=True)\n",
    "importance_xgb = sorted(importance_xgb, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet = sorted(importance_tabnet, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet_paper = sorted(importance_tabnet_paper, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x424.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = shap.TreeExplainer(model_xgb).shap_values(train_X)\n",
    "shap.summary_plot(shap_values, train_X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame([train.columns[x[0]] for x in importance_lgbm], columns=[\"LightGBM\"])\n",
    "df_compare[\"XGBoost\"] = [x[0] for x in importance_xgb]\n",
    "df_compare[\"SHAP_XGBoost\"] = train_X.columns[np.argsort(np.abs(shap_values).mean(0))][::-1]\n",
    "df_compare[\"TabNet\"] = [train.columns[x[0]] for x in importance_tabnet]\n",
    "df_compare[\"TabNet_Paper\"] = [train.columns[x[0]] for x in importance_tabnet_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X3</td>\n",
       "      <td>X3</td>\n",
       "      <td>X3</td>\n",
       "      <td>X2</td>\n",
       "      <td>X8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X2</td>\n",
       "      <td>X10</td>\n",
       "      <td>X2</td>\n",
       "      <td>X3</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X1</td>\n",
       "      <td>X4</td>\n",
       "      <td>X1</td>\n",
       "      <td>X9</td>\n",
       "      <td>X4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X6</td>\n",
       "      <td>X9</td>\n",
       "      <td>X10</td>\n",
       "      <td>X8</td>\n",
       "      <td>X10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X5</td>\n",
       "      <td>X1</td>\n",
       "      <td>X6</td>\n",
       "      <td>X5</td>\n",
       "      <td>X7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X10</td>\n",
       "      <td>X2</td>\n",
       "      <td>X4</td>\n",
       "      <td>X10</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X8</td>\n",
       "      <td>X7</td>\n",
       "      <td>X5</td>\n",
       "      <td>X1</td>\n",
       "      <td>X5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X4</td>\n",
       "      <td>X5</td>\n",
       "      <td>X9</td>\n",
       "      <td>X4</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X7</td>\n",
       "      <td>X6</td>\n",
       "      <td>X8</td>\n",
       "      <td>X6</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X9</td>\n",
       "      <td>X8</td>\n",
       "      <td>X7</td>\n",
       "      <td>X7</td>\n",
       "      <td>X6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM XGBoost SHAP_XGBoost TabNet TabNet_Paper\n",
       "0        X0      X0           X0     X0           X0\n",
       "1        X3      X3           X3     X2           X8\n",
       "2        X2     X10           X2     X3           X3\n",
       "3        X1      X4           X1     X9           X4\n",
       "4        X6      X9          X10     X8          X10\n",
       "5        X5      X1           X6     X5           X7\n",
       "6       X10      X2           X4    X10           X1\n",
       "7        X8      X7           X5     X1           X5\n",
       "8        X4      X5           X9     X4           X9\n",
       "9        X7      X6           X8     X6           X2\n",
       "10       X9      X8           X7     X7           X6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:2, col1]) & set(df_compare.loc[:2, col2])))\n",
    "        top_3.append(d)\n",
    "top_3_data = pd.DataFrame(top_3, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             3             3       3             2        2\n",
       "SHAP_XGBoost         3             3       3             2        2\n",
       "TabNet               3             3       3             2        2\n",
       "TabNet_Paper         2             2       2             3        2\n",
       "XGBoost              2             2       2             2        3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 3 признака из каждой и обучить бустинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:4, col1]) & set(df_compare.loc[:4, col2])))\n",
    "        top_5.append(d)\n",
    "top_5_data = pd.DataFrame(top_5, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             5             4       3             2        2\n",
       "SHAP_XGBoost         4             5       3             3        3\n",
       "TabNet               3             3       5             3        3\n",
       "TabNet_Paper         2             3       3             5        4\n",
       "XGBoost              2             3       3             4        5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_5_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:9, col1]) & set(df_compare.loc[:9, col2])))\n",
    "        top_10.append(d)\n",
    "top_10_data = pd.DataFrame(top_10, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM            10             9       9             9        9\n",
       "SHAP_XGBoost         9            10      10             9        9\n",
       "TabNet               9            10      10             9        9\n",
       "TabNet_Paper         9             9       9            10        9\n",
       "XGBoost              9             9       9             9       10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_feats = {}\n",
    "top3_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\"]\n",
    "top3_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\"]\n",
    "top3_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_feats = {}\n",
    "top10_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\", \"occupation\", \"education_num\", \"capital_gain\", \"education\", \"workclass\", \"capital_loss\", \"native_country\"]\n",
    "top10_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\", \"relationship\", \"education_num\", \"occupation\", \"fnlwgt\", \"hours_per_week\", \"sex\", \"capital_loss\"]\n",
    "top10_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\", \"hours_per_week\", \"education_num\", \"capital_gain\", \"education\", \"sex\", \"workclass\", \"capital_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-817f43cedb3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop3_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop3_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcat_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "top3_results = []\n",
    "for model, feats in top3_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([train.columns[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top3_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top3_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top3_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top3_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_scores = pd.DataFrame(top3_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.805527</td>\n",
       "      <td>0.851631</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.864625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.824770</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.857539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.769089</td>\n",
       "      <td>0.751890</td>\n",
       "      <td>0.760491</td>\n",
       "      <td>0.727796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.805527  0.851631  0.819652  0.864625\n",
       "tabnet    0.824770  0.864272  0.819652  0.857539\n",
       "xgboost   0.769089  0.751890  0.760491  0.727796"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.79592 |  0:00:12s\n",
      "epoch 1  | loss: 0.49582 |  0:00:25s\n",
      "epoch 2  | loss: 0.44158 |  0:00:40s\n",
      "epoch 3  | loss: 0.40275 |  0:00:53s\n",
      "epoch 4  | loss: 0.40626 |  0:01:05s\n",
      "epoch 5  | loss: 0.4009  |  0:01:18s\n",
      "epoch 6  | loss: 0.39774 |  0:01:30s\n",
      "epoch 7  | loss: 0.39294 |  0:01:43s\n",
      "epoch 8  | loss: 0.3906  |  0:01:57s\n",
      "epoch 9  | loss: 0.39566 |  0:02:17s\n",
      "epoch 10 | loss: 0.3941  |  0:02:54s\n",
      "epoch 11 | loss: 0.39292 |  0:03:31s\n",
      "epoch 12 | loss: 0.39145 |  0:04:11s\n",
      "epoch 13 | loss: 0.3886  |  0:04:34s\n",
      "epoch 14 | loss: 0.39061 |  0:05:00s\n",
      "epoch 15 | loss: 0.39403 |  0:05:23s\n",
      "epoch 16 | loss: 0.38763 |  0:05:47s\n",
      "epoch 17 | loss: 0.38817 |  0:06:08s\n",
      "epoch 18 | loss: 0.39708 |  0:06:32s\n",
      "epoch 19 | loss: 0.39374 |  0:06:56s\n",
      "epoch 20 | loss: 0.3895  |  0:07:21s\n",
      "epoch 21 | loss: 0.38912 |  0:07:45s\n",
      "epoch 22 | loss: 0.38642 |  0:08:08s\n",
      "epoch 23 | loss: 0.3847  |  0:08:33s\n",
      "epoch 24 | loss: 0.38419 |  0:08:57s\n",
      "epoch 25 | loss: 0.38397 |  0:09:20s\n",
      "epoch 26 | loss: 0.38094 |  0:09:44s\n",
      "epoch 27 | loss: 0.38124 |  0:10:07s\n",
      "epoch 28 | loss: 0.38337 |  0:10:31s\n",
      "epoch 29 | loss: 0.38498 |  0:10:55s\n",
      "epoch 30 | loss: 0.38105 |  0:11:19s\n",
      "epoch 31 | loss: 0.38232 |  0:11:40s\n",
      "epoch 32 | loss: 0.3815  |  0:12:04s\n",
      "epoch 33 | loss: 0.38328 |  0:12:26s\n",
      "epoch 34 | loss: 0.37821 |  0:12:49s\n",
      "epoch 35 | loss: 0.3803  |  0:13:13s\n",
      "epoch 36 | loss: 0.37915 |  0:13:36s\n",
      "epoch 37 | loss: 0.37989 |  0:13:59s\n",
      "epoch 38 | loss: 0.39247 |  0:14:23s\n",
      "epoch 39 | loss: 0.3804  |  0:14:46s\n",
      "epoch 40 | loss: 0.37794 |  0:15:11s\n",
      "epoch 41 | loss: 0.37671 |  0:15:32s\n",
      "epoch 42 | loss: 0.37527 |  0:15:54s\n",
      "epoch 43 | loss: 0.37477 |  0:16:15s\n",
      "epoch 44 | loss: 0.38458 |  0:16:38s\n",
      "epoch 45 | loss: 0.38768 |  0:17:00s\n",
      "epoch 46 | loss: 0.37762 |  0:17:25s\n",
      "epoch 47 | loss: 0.37628 |  0:17:48s\n",
      "epoch 48 | loss: 0.37779 |  0:18:10s\n",
      "epoch 49 | loss: 0.37808 |  0:18:33s\n",
      "epoch 50 | loss: 0.37675 |  0:18:56s\n",
      "epoch 51 | loss: 0.37481 |  0:19:20s\n",
      "epoch 52 | loss: 0.37458 |  0:19:43s\n",
      "epoch 53 | loss: 0.37851 |  0:20:06s\n",
      "epoch 54 | loss: 0.37758 |  0:20:30s\n",
      "epoch 55 | loss: 0.38001 |  0:20:51s\n",
      "epoch 56 | loss: 0.38308 |  0:21:15s\n",
      "epoch 57 | loss: 0.38137 |  0:21:39s\n",
      "epoch 58 | loss: 0.37925 |  0:22:01s\n",
      "epoch 59 | loss: 0.38585 |  0:22:24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:08] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:42:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.90432 |  0:00:23s\n",
      "epoch 1  | loss: 0.39276 |  0:00:49s\n",
      "epoch 2  | loss: 0.34943 |  0:01:11s\n",
      "epoch 3  | loss: 0.34461 |  0:01:34s\n",
      "epoch 4  | loss: 0.34024 |  0:01:57s\n",
      "epoch 5  | loss: 0.34186 |  0:02:20s\n",
      "epoch 6  | loss: 0.34383 |  0:02:42s\n",
      "epoch 7  | loss: 0.33729 |  0:03:08s\n",
      "epoch 8  | loss: 0.33883 |  0:03:30s\n",
      "epoch 9  | loss: 0.33975 |  0:03:54s\n",
      "epoch 10 | loss: 0.34485 |  0:04:17s\n",
      "epoch 11 | loss: 0.33227 |  0:04:40s\n",
      "epoch 12 | loss: 0.33144 |  0:05:06s\n",
      "epoch 13 | loss: 0.3314  |  0:05:29s\n",
      "epoch 14 | loss: 0.33928 |  0:05:50s\n",
      "epoch 15 | loss: 0.32989 |  0:06:12s\n",
      "epoch 16 | loss: 0.33309 |  0:06:33s\n",
      "epoch 17 | loss: 0.33441 |  0:06:56s\n",
      "epoch 18 | loss: 0.33631 |  0:07:21s\n",
      "epoch 19 | loss: 0.32965 |  0:07:44s\n",
      "epoch 20 | loss: 0.33031 |  0:08:08s\n",
      "epoch 21 | loss: 0.32679 |  0:08:31s\n",
      "epoch 22 | loss: 0.32387 |  0:08:53s\n",
      "epoch 23 | loss: 0.32129 |  0:09:18s\n",
      "epoch 24 | loss: 0.3256  |  0:09:40s\n",
      "epoch 25 | loss: 0.33124 |  0:10:03s\n",
      "epoch 26 | loss: 0.32599 |  0:10:26s\n",
      "epoch 27 | loss: 0.32683 |  0:10:49s\n",
      "epoch 28 | loss: 0.32928 |  0:11:12s\n",
      "epoch 29 | loss: 0.32668 |  0:11:35s\n",
      "epoch 30 | loss: 0.32345 |  0:11:58s\n",
      "epoch 31 | loss: 0.32416 |  0:12:21s\n",
      "epoch 32 | loss: 0.32507 |  0:12:43s\n",
      "epoch 33 | loss: 0.32404 |  0:13:05s\n",
      "epoch 34 | loss: 0.32054 |  0:13:29s\n",
      "epoch 35 | loss: 0.32212 |  0:13:53s\n",
      "epoch 36 | loss: 0.32217 |  0:14:14s\n",
      "epoch 37 | loss: 0.31913 |  0:14:37s\n",
      "epoch 38 | loss: 0.32162 |  0:15:00s\n",
      "epoch 39 | loss: 0.32277 |  0:15:23s\n",
      "epoch 40 | loss: 0.31707 |  0:15:46s\n",
      "epoch 41 | loss: 0.31975 |  0:16:09s\n",
      "epoch 42 | loss: 0.3171  |  0:16:31s\n",
      "epoch 43 | loss: 0.32048 |  0:16:55s\n",
      "epoch 44 | loss: 0.32208 |  0:17:17s\n",
      "epoch 45 | loss: 0.31896 |  0:17:41s\n",
      "epoch 46 | loss: 0.31771 |  0:18:03s\n",
      "epoch 47 | loss: 0.32248 |  0:18:25s\n",
      "epoch 48 | loss: 0.31958 |  0:18:48s\n",
      "epoch 49 | loss: 0.31565 |  0:19:12s\n",
      "epoch 50 | loss: 0.32475 |  0:19:35s\n",
      "epoch 51 | loss: 0.32692 |  0:20:00s\n",
      "epoch 52 | loss: 0.32314 |  0:20:21s\n",
      "epoch 53 | loss: 0.31824 |  0:20:44s\n",
      "epoch 54 | loss: 0.3168  |  0:21:06s\n",
      "epoch 55 | loss: 0.3186  |  0:21:29s\n",
      "epoch 56 | loss: 0.3175  |  0:21:51s\n",
      "epoch 57 | loss: 0.32138 |  0:22:14s\n",
      "epoch 58 | loss: 0.31531 |  0:22:37s\n",
      "epoch 59 | loss: 0.32162 |  0:22:59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.88531 |  0:00:22s\n",
      "epoch 1  | loss: 0.45036 |  0:00:46s\n",
      "epoch 2  | loss: 0.38011 |  0:01:11s\n",
      "epoch 3  | loss: 0.37047 |  0:01:34s\n",
      "epoch 4  | loss: 0.36544 |  0:01:56s\n",
      "epoch 5  | loss: 0.35333 |  0:02:18s\n",
      "epoch 6  | loss: 0.34735 |  0:02:40s\n",
      "epoch 7  | loss: 0.34333 |  0:03:04s\n",
      "epoch 8  | loss: 0.33326 |  0:03:26s\n",
      "epoch 9  | loss: 0.33396 |  0:03:48s\n",
      "epoch 10 | loss: 0.3291  |  0:04:10s\n",
      "epoch 11 | loss: 0.33335 |  0:04:33s\n",
      "epoch 12 | loss: 0.33609 |  0:04:56s\n",
      "epoch 13 | loss: 0.3272  |  0:05:22s\n",
      "epoch 14 | loss: 0.32744 |  0:05:46s\n",
      "epoch 15 | loss: 0.32778 |  0:06:08s\n",
      "epoch 16 | loss: 0.33217 |  0:06:31s\n",
      "epoch 17 | loss: 0.33119 |  0:06:55s\n",
      "epoch 18 | loss: 0.32972 |  0:07:19s\n",
      "epoch 19 | loss: 0.32382 |  0:07:44s\n",
      "epoch 20 | loss: 0.32044 |  0:08:07s\n",
      "epoch 21 | loss: 0.32228 |  0:08:31s\n",
      "epoch 22 | loss: 0.32318 |  0:08:53s\n",
      "epoch 23 | loss: 0.31931 |  0:09:17s\n",
      "epoch 24 | loss: 0.31832 |  0:09:43s\n",
      "epoch 25 | loss: 0.32146 |  0:10:08s\n",
      "epoch 26 | loss: 0.31939 |  0:10:31s\n",
      "epoch 27 | loss: 0.32324 |  0:10:54s\n",
      "epoch 28 | loss: 0.32076 |  0:11:16s\n",
      "epoch 29 | loss: 0.31843 |  0:11:41s\n",
      "epoch 30 | loss: 0.32007 |  0:12:03s\n",
      "epoch 31 | loss: 0.31646 |  0:12:26s\n",
      "epoch 32 | loss: 0.31788 |  0:12:49s\n",
      "epoch 33 | loss: 0.32226 |  0:13:11s\n",
      "epoch 34 | loss: 0.32327 |  0:13:36s\n",
      "epoch 35 | loss: 0.31879 |  0:14:00s\n",
      "epoch 36 | loss: 0.32053 |  0:14:22s\n",
      "epoch 37 | loss: 0.31749 |  0:14:44s\n",
      "epoch 38 | loss: 0.31663 |  0:15:06s\n",
      "epoch 39 | loss: 0.31701 |  0:15:29s\n",
      "epoch 40 | loss: 0.31846 |  0:15:54s\n",
      "epoch 41 | loss: 0.31558 |  0:16:17s\n",
      "epoch 42 | loss: 0.31806 |  0:16:39s\n",
      "epoch 43 | loss: 0.3132  |  0:17:01s\n",
      "epoch 44 | loss: 0.31541 |  0:17:24s\n",
      "epoch 45 | loss: 0.31546 |  0:17:46s\n",
      "epoch 46 | loss: 0.31311 |  0:18:12s\n",
      "epoch 47 | loss: 0.31327 |  0:18:35s\n",
      "epoch 48 | loss: 0.3125  |  0:18:59s\n",
      "epoch 49 | loss: 0.31129 |  0:19:23s\n",
      "epoch 50 | loss: 0.31289 |  0:19:46s\n",
      "epoch 51 | loss: 0.31092 |  0:20:12s\n",
      "epoch 52 | loss: 0.31229 |  0:20:36s\n",
      "epoch 53 | loss: 0.31126 |  0:20:58s\n",
      "epoch 54 | loss: 0.309   |  0:21:20s\n",
      "epoch 55 | loss: 0.31072 |  0:21:42s\n",
      "epoch 56 | loss: 0.31349 |  0:22:05s\n",
      "epoch 57 | loss: 0.3108  |  0:22:29s\n",
      "epoch 58 | loss: 0.31376 |  0:22:51s\n",
      "epoch 59 | loss: 0.32204 |  0:23:14s\n"
     ]
    }
   ],
   "source": [
    "top10_results = []\n",
    "for model, feats in top10_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([column_names[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top10_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top10_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top10_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top10_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_scores = pd.DataFrame(top10_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.856704</td>\n",
       "      <td>0.909560</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.913265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.911028</td>\n",
       "      <td>0.869396</td>\n",
       "      <td>0.916778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.826612</td>\n",
       "      <td>0.851441</td>\n",
       "      <td>0.835619</td>\n",
       "      <td>0.867916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.856704  0.909560  0.857318  0.913265\n",
       "tabnet    0.859570  0.911028  0.869396  0.916778\n",
       "xgboost   0.826612  0.851441  0.835619  0.867916"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
