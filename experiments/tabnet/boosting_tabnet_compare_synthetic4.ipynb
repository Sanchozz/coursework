{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pickle\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "from bo_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tuned = {\n",
    "    \"learning_rate\" : 0.2618422323665017, \n",
    "    \"max_depth\" : 11, \n",
    "    \"n_estimators\" : 965\n",
    "}\n",
    "# lgbm_tuned += LIGHTGBM_PARAMS\n",
    "\n",
    "xgb_tuned = {\n",
    "    \"learning_rate\" : 0.3535422004334621, \n",
    "    \"max_depth\" : 7, \n",
    "    \"n_estimators\" : 969\n",
    "}\n",
    "# xgb_tuned += XGBOOST_PARAMS\n",
    "\n",
    "tabnet_tuned = {\n",
    "    \"gamma\" : 1.0840374047235146, \n",
    "    \"lambda_sparse\" : 0.07756898575730785, \n",
    "    \"n_steps\" : 8,\n",
    "    \"n_a\" : 16,\n",
    "    \"momentum\" : 0.6,\n",
    "}\n",
    "tabnet_tuned[\"n_d\"] = tabnet_tuned[\"n_a\"]\n",
    "\n",
    "tabnet_paper = {\n",
    "    \"gamma\" : 1.5, \n",
    "    \"lambda_sparse\" : 0.005, \n",
    "    \"n_steps\" : 5,\n",
    "    \"n_a\" : 16,\n",
    "    \"momentum\" : 0.7,\n",
    "}\n",
    "tabnet_paper[\"n_d\"] = tabnet_paper[\"n_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/synthetic/syn4/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/synthetic/syn4/train.csv\")\n",
    "valid = pd.read_csv(\"data/synthetic/syn4/val.csv\")\n",
    "test = pd.read_csv(\"data/synthetic/syn4/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432321</td>\n",
       "      <td>0.535990</td>\n",
       "      <td>-0.074400</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>0.928816</td>\n",
       "      <td>-0.159656</td>\n",
       "      <td>-0.436071</td>\n",
       "      <td>-0.275048</td>\n",
       "      <td>2.208550</td>\n",
       "      <td>0.578329</td>\n",
       "      <td>3.727226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211749</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.387897</td>\n",
       "      <td>-1.593211</td>\n",
       "      <td>-0.212643</td>\n",
       "      <td>-0.641464</td>\n",
       "      <td>0.791923</td>\n",
       "      <td>-0.725224</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>-0.485611</td>\n",
       "      <td>3.417863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.409733</td>\n",
       "      <td>1.137426</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>-0.027784</td>\n",
       "      <td>-0.409733</td>\n",
       "      <td>1.137426</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>-0.027784</td>\n",
       "      <td>0.857031</td>\n",
       "      <td>0.758963</td>\n",
       "      <td>-1.550774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.902713</td>\n",
       "      <td>-0.370852</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.394262</td>\n",
       "      <td>0.789984</td>\n",
       "      <td>0.965404</td>\n",
       "      <td>-0.125416</td>\n",
       "      <td>0.215990</td>\n",
       "      <td>0.294507</td>\n",
       "      <td>0.353048</td>\n",
       "      <td>1.864526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.108205</td>\n",
       "      <td>0.431700</td>\n",
       "      <td>-0.180731</td>\n",
       "      <td>0.453472</td>\n",
       "      <td>-1.408888</td>\n",
       "      <td>-1.110889</td>\n",
       "      <td>1.786660</td>\n",
       "      <td>-0.454689</td>\n",
       "      <td>0.512158</td>\n",
       "      <td>1.269235</td>\n",
       "      <td>2.356497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0  0.432321  0.535990 -0.074400  0.088705  0.928816 -0.159656 -0.436071   \n",
       "1  0.211749  0.007537  0.387897 -1.593211 -0.212643 -0.641464  0.791923   \n",
       "2 -0.409733  1.137426  0.090188 -0.027784 -0.409733  1.137426  0.090188   \n",
       "3 -0.902713 -0.370852  0.003299  0.394262  0.789984  0.965404 -0.125416   \n",
       "4 -0.108205  0.431700 -0.180731  0.453472 -1.408888 -1.110889  1.786660   \n",
       "\n",
       "         X7        X8        X9       X10  TARGET  \n",
       "0 -0.275048  2.208550  0.578329  3.727226       0  \n",
       "1 -0.725224  0.178527 -0.485611  3.417863       0  \n",
       "2 -0.027784  0.857031  0.758963 -1.550774       0  \n",
       "3  0.215990  0.294507  0.353048  1.864526       0  \n",
       "4 -0.454689  0.512158  1.269235  2.356497       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop([\"TARGET\"], axis=1)\n",
    "train_y = train[\"TARGET\"]\n",
    "\n",
    "test_X = test.drop([\"TARGET\"], axis=1)\n",
    "test_y = test[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.2618422323665017, max_depth=11, metric='auc',\n",
       "               n_estimators=965, objective='binary', random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier(**{**lgbm_tuned, **LIGHTGBM_PARAMS})\n",
    "model_lgbm.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:45:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3535422004334621, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=969, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "model_xgb.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABNET_PARAMS[\"verbose\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.8911  |  0:00:01s\n",
      "epoch 1  | loss: 0.49661 |  0:00:03s\n",
      "epoch 2  | loss: 0.40973 |  0:00:05s\n",
      "epoch 3  | loss: 0.35334 |  0:00:07s\n",
      "epoch 4  | loss: 0.32101 |  0:00:09s\n",
      "epoch 5  | loss: 0.29268 |  0:00:11s\n",
      "epoch 6  | loss: 0.29315 |  0:00:13s\n",
      "epoch 7  | loss: 0.29523 |  0:00:15s\n",
      "epoch 8  | loss: 0.26286 |  0:00:17s\n",
      "epoch 9  | loss: 0.27878 |  0:00:19s\n",
      "epoch 10 | loss: 0.27583 |  0:00:21s\n",
      "epoch 11 | loss: 0.24984 |  0:00:22s\n",
      "epoch 12 | loss: 0.23627 |  0:00:24s\n",
      "epoch 13 | loss: 0.22491 |  0:00:26s\n",
      "epoch 14 | loss: 0.21999 |  0:00:28s\n",
      "epoch 15 | loss: 0.21264 |  0:00:30s\n",
      "epoch 16 | loss: 0.20669 |  0:00:32s\n",
      "epoch 17 | loss: 0.19903 |  0:00:34s\n",
      "epoch 18 | loss: 0.18885 |  0:00:36s\n",
      "epoch 19 | loss: 0.18028 |  0:00:38s\n",
      "epoch 20 | loss: 0.16858 |  0:00:39s\n",
      "epoch 21 | loss: 0.16872 |  0:00:41s\n",
      "epoch 22 | loss: 0.17268 |  0:00:43s\n",
      "epoch 23 | loss: 0.16577 |  0:00:45s\n",
      "epoch 24 | loss: 0.15859 |  0:00:47s\n",
      "epoch 25 | loss: 0.16139 |  0:00:49s\n",
      "epoch 26 | loss: 0.15393 |  0:00:51s\n",
      "epoch 27 | loss: 0.1612  |  0:00:53s\n",
      "epoch 28 | loss: 0.15325 |  0:00:55s\n",
      "epoch 29 | loss: 0.153   |  0:00:56s\n",
      "epoch 30 | loss: 0.14504 |  0:00:58s\n",
      "epoch 31 | loss: 0.14579 |  0:01:00s\n",
      "epoch 32 | loss: 0.14243 |  0:01:02s\n",
      "epoch 33 | loss: 0.1468  |  0:01:04s\n",
      "epoch 34 | loss: 0.14634 |  0:01:06s\n",
      "epoch 35 | loss: 0.1392  |  0:01:09s\n",
      "epoch 36 | loss: 0.13461 |  0:01:11s\n",
      "epoch 37 | loss: 0.1377  |  0:01:14s\n",
      "epoch 38 | loss: 0.13684 |  0:01:15s\n",
      "epoch 39 | loss: 0.13466 |  0:01:17s\n",
      "epoch 40 | loss: 0.1349  |  0:01:19s\n",
      "epoch 41 | loss: 0.12742 |  0:01:21s\n",
      "epoch 42 | loss: 0.12982 |  0:01:23s\n",
      "epoch 43 | loss: 0.13172 |  0:01:25s\n",
      "epoch 44 | loss: 0.13341 |  0:01:27s\n",
      "epoch 45 | loss: 0.13164 |  0:01:29s\n",
      "epoch 46 | loss: 0.12511 |  0:01:30s\n",
      "epoch 47 | loss: 0.12433 |  0:01:32s\n",
      "epoch 48 | loss: 0.13004 |  0:01:34s\n",
      "epoch 49 | loss: 0.12861 |  0:01:36s\n",
      "epoch 50 | loss: 0.12338 |  0:01:38s\n",
      "epoch 51 | loss: 0.1227  |  0:01:40s\n",
      "epoch 52 | loss: 0.12996 |  0:01:42s\n",
      "epoch 53 | loss: 0.12352 |  0:01:44s\n",
      "epoch 54 | loss: 0.116   |  0:01:45s\n",
      "epoch 55 | loss: 0.1159  |  0:01:47s\n",
      "epoch 56 | loss: 0.11904 |  0:01:49s\n",
      "epoch 57 | loss: 0.12145 |  0:01:51s\n",
      "epoch 58 | loss: 0.11841 |  0:01:53s\n",
      "epoch 59 | loss: 0.11515 |  0:01:55s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS})\n",
    "model_tabnet.fit(train_X.values, train_y.values, max_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.96179 |  0:00:01s\n",
      "epoch 1  | loss: 0.61489 |  0:00:02s\n",
      "epoch 2  | loss: 0.54705 |  0:00:03s\n",
      "epoch 3  | loss: 0.46386 |  0:00:04s\n",
      "epoch 4  | loss: 0.42644 |  0:00:05s\n",
      "epoch 5  | loss: 0.39644 |  0:00:06s\n",
      "epoch 6  | loss: 0.3692  |  0:00:07s\n",
      "epoch 7  | loss: 0.34453 |  0:00:08s\n",
      "epoch 8  | loss: 0.33003 |  0:00:09s\n",
      "epoch 9  | loss: 0.31802 |  0:00:10s\n",
      "epoch 10 | loss: 0.31112 |  0:00:12s\n",
      "epoch 11 | loss: 0.28945 |  0:00:13s\n",
      "epoch 12 | loss: 0.2865  |  0:00:14s\n",
      "epoch 13 | loss: 0.29046 |  0:00:15s\n",
      "epoch 14 | loss: 0.27357 |  0:00:16s\n",
      "epoch 15 | loss: 0.26464 |  0:00:17s\n",
      "epoch 16 | loss: 0.25747 |  0:00:18s\n",
      "epoch 17 | loss: 0.25287 |  0:00:19s\n",
      "epoch 18 | loss: 0.24576 |  0:00:20s\n",
      "epoch 19 | loss: 0.23907 |  0:00:22s\n",
      "epoch 20 | loss: 0.23145 |  0:00:23s\n",
      "epoch 21 | loss: 0.2289  |  0:00:24s\n",
      "epoch 22 | loss: 0.22354 |  0:00:26s\n",
      "epoch 23 | loss: 0.21779 |  0:00:29s\n",
      "epoch 24 | loss: 0.21744 |  0:00:31s\n",
      "epoch 25 | loss: 0.21388 |  0:00:33s\n",
      "epoch 26 | loss: 0.20565 |  0:00:36s\n",
      "epoch 27 | loss: 0.20657 |  0:00:38s\n",
      "epoch 28 | loss: 0.20627 |  0:00:41s\n",
      "epoch 29 | loss: 0.21037 |  0:00:43s\n",
      "epoch 30 | loss: 0.20401 |  0:00:46s\n",
      "epoch 31 | loss: 0.19803 |  0:00:48s\n",
      "epoch 32 | loss: 0.19826 |  0:00:50s\n",
      "epoch 33 | loss: 0.18992 |  0:00:53s\n",
      "epoch 34 | loss: 0.18963 |  0:00:55s\n",
      "epoch 35 | loss: 0.18746 |  0:00:58s\n",
      "epoch 36 | loss: 0.18467 |  0:01:00s\n",
      "epoch 37 | loss: 0.18026 |  0:01:02s\n",
      "epoch 38 | loss: 0.18156 |  0:01:05s\n",
      "epoch 39 | loss: 0.17735 |  0:01:08s\n",
      "epoch 40 | loss: 0.17048 |  0:01:10s\n",
      "epoch 41 | loss: 0.17216 |  0:01:13s\n",
      "epoch 42 | loss: 0.16568 |  0:01:16s\n",
      "epoch 43 | loss: 0.16732 |  0:01:18s\n",
      "epoch 44 | loss: 0.15932 |  0:01:21s\n",
      "epoch 45 | loss: 0.15309 |  0:01:24s\n",
      "epoch 46 | loss: 0.15433 |  0:01:27s\n",
      "epoch 47 | loss: 0.155   |  0:01:29s\n",
      "epoch 48 | loss: 0.15668 |  0:01:32s\n",
      "epoch 49 | loss: 0.15089 |  0:01:35s\n",
      "epoch 50 | loss: 0.1598  |  0:01:38s\n",
      "epoch 51 | loss: 0.15455 |  0:01:41s\n",
      "epoch 52 | loss: 0.16828 |  0:01:44s\n",
      "epoch 53 | loss: 0.16249 |  0:01:46s\n",
      "epoch 54 | loss: 0.16211 |  0:01:49s\n",
      "epoch 55 | loss: 0.1612  |  0:01:52s\n",
      "epoch 56 | loss: 0.16028 |  0:01:55s\n",
      "epoch 57 | loss: 0.15418 |  0:01:57s\n",
      "epoch 58 | loss: 0.16603 |  0:02:00s\n",
      "epoch 59 | loss: 0.1638  |  0:02:03s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet_paper = TabNetClassifier(**{**tabnet_paper, **TABNET_PARAMS})\n",
    "model_tabnet_paper.fit(train_X.values, train_y.values, max_epochs=60, batch_size=3000, virtual_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet, f)\n",
    "with open('model_tabnet_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet_paper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'rb') as f:\n",
    "    model_tabnet = pickle.load(f)\n",
    "with open('model_tabnet_paper.pickle', 'rb') as f:\n",
    "    model_tabnet_paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM auc:  0.993907\n",
      "XGBoost auc:  0.994021\n",
      "TabNet auc:  0.992485\n",
      "TabNet Paper auc:  0.981856\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM auc: \", round(roc_auc_score(test_y, model_lgbm.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"XGBoost auc: \", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"TabNet auc: \", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X.values)[:, 1]), 6))\n",
    "print(\"TabNet Paper auc: \", round(roc_auc_score(test_y, model_tabnet_paper.predict_proba(test_X.values)[:, 1]), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM acc:  0.976016\n",
      "XGBoost acc:  0.974017\n",
      "TabNet acc:  0.957362\n",
      "TabNet Paper acc:  0.944704\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM acc: \", round(accuracy_score(test_y, model_lgbm.predict(test_X)), 6))\n",
    "print(\"XGBoost acc: \", round(accuracy_score(test_y, model_xgb.predict(test_X)), 6))\n",
    "print(\"TabNet acc: \", round(accuracy_score(test_y, model_tabnet.predict(test_X.values)), 6))\n",
    "print(\"TabNet Paper acc: \", round(accuracy_score(test_y, model_tabnet_paper.predict(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM log_loss:  0.197438\n",
      "XGBoost log_loss:  0.108353\n",
      "TabNet log_loss:  0.099477\n",
      "TabNet Paper log_loss:  0.155773\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM log_loss: \", round(log_loss(test_y, model_lgbm.predict_proba(test_X)), 6))\n",
    "print(\"XGBoost log_loss: \", round(log_loss(test_y, model_xgb.predict_proba(test_X)), 6))\n",
    "print(\"TabNet log_loss: \", round(log_loss(test_y, model_tabnet.predict_proba(test_X.values)), 6))\n",
    "print(\"TabNet Paper log_loss: \", round(log_loss(test_y, model_tabnet_paper.predict_proba(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = list(enumerate(model_lgbm.feature_importances_))\n",
    "importance_xgb = model_xgb.get_booster().get_score(importance_type='weight').items()\n",
    "importance_tabnet = list(enumerate(model_tabnet.feature_importances_))\n",
    "importance_tabnet_paper = list(enumerate(model_tabnet_paper.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = sorted(importance_lgbm, key=lambda x: x[1], reverse=True)\n",
    "importance_xgb = sorted(importance_xgb, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet = sorted(importance_tabnet, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet_paper = sorted(importance_tabnet_paper, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x424.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = shap.TreeExplainer(model_xgb).shap_values(train_X)\n",
    "shap.summary_plot(shap_values, train_X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame([train.columns[x[0]] for x in importance_lgbm], columns=[\"LightGBM\"])\n",
    "df_compare[\"XGBoost\"] = [x[0] for x in importance_xgb]\n",
    "df_compare[\"SHAP_XGBoost\"] = train_X.columns[np.argsort(np.abs(shap_values).mean(0))][::-1]\n",
    "df_compare[\"TabNet\"] = [train.columns[x[0]] for x in importance_tabnet]\n",
    "df_compare[\"TabNet_Paper\"] = [train.columns[x[0]] for x in importance_tabnet_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "      <td>X2</td>\n",
       "      <td>X10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "      <td>X2</td>\n",
       "      <td>X10</td>\n",
       "      <td>X6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X10</td>\n",
       "      <td>X1</td>\n",
       "      <td>X0</td>\n",
       "      <td>X1</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X8</td>\n",
       "      <td>X2</td>\n",
       "      <td>X1</td>\n",
       "      <td>X0</td>\n",
       "      <td>X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X9</td>\n",
       "      <td>X8</td>\n",
       "      <td>X6</td>\n",
       "      <td>X6</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X3</td>\n",
       "      <td>X9</td>\n",
       "      <td>X9</td>\n",
       "      <td>X9</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X6</td>\n",
       "      <td>X3</td>\n",
       "      <td>X4</td>\n",
       "      <td>X4</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X2</td>\n",
       "      <td>X6</td>\n",
       "      <td>X3</td>\n",
       "      <td>X7</td>\n",
       "      <td>X7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X4</td>\n",
       "      <td>X4</td>\n",
       "      <td>X7</td>\n",
       "      <td>X3</td>\n",
       "      <td>X5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X7</td>\n",
       "      <td>X7</td>\n",
       "      <td>X8</td>\n",
       "      <td>X5</td>\n",
       "      <td>X8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X5</td>\n",
       "      <td>X5</td>\n",
       "      <td>X5</td>\n",
       "      <td>X8</td>\n",
       "      <td>X4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM XGBoost SHAP_XGBoost TabNet TabNet_Paper\n",
       "0        X1     X10          X10     X2          X10\n",
       "1        X0      X0           X2    X10           X6\n",
       "2       X10      X1           X0     X1           X1\n",
       "3        X8      X2           X1     X0           X0\n",
       "4        X9      X8           X6     X6           X9\n",
       "5        X3      X9           X9     X9           X3\n",
       "6        X6      X3           X4     X4           X2\n",
       "7        X2      X6           X3     X7           X7\n",
       "8        X4      X4           X7     X3           X5\n",
       "9        X7      X7           X8     X5           X8\n",
       "10       X5      X5           X5     X8           X4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:2, col1]) & set(df_compare.loc[:2, col2])))\n",
    "        top_3.append(d)\n",
    "top_3_data = pd.DataFrame(top_3, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             3             2       2             2        3\n",
       "SHAP_XGBoost         2             3       2             1        2\n",
       "TabNet               2             2       3             2        2\n",
       "TabNet_Paper         2             1       2             3        2\n",
       "XGBoost              3             2       2             2        3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 3 признака из каждой и обучить бустинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:4, col1]) & set(df_compare.loc[:4, col2])))\n",
    "        top_5.append(d)\n",
    "top_5_data = pd.DataFrame(top_5, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             5             3       3             4        4\n",
       "SHAP_XGBoost         3             5       5             4        4\n",
       "TabNet               3             5       5             4        4\n",
       "TabNet_Paper         4             4       4             5        3\n",
       "XGBoost              4             4       4             3        5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_5_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:9, col1]) & set(df_compare.loc[:9, col2])))\n",
    "        top_10.append(d)\n",
    "top_10_data = pd.DataFrame(top_10, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM            10            10       9             9       10\n",
       "SHAP_XGBoost        10            10       9             9       10\n",
       "TabNet               9             9      10             9        9\n",
       "TabNet_Paper         9             9       9            10        9\n",
       "XGBoost             10            10       9             9       10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_feats = {}\n",
    "top3_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\"]\n",
    "top3_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\"]\n",
    "top3_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_feats = {}\n",
    "top10_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\", \"occupation\", \"education_num\", \"capital_gain\", \"education\", \"workclass\", \"capital_loss\", \"native_country\"]\n",
    "top10_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\", \"relationship\", \"education_num\", \"occupation\", \"fnlwgt\", \"hours_per_week\", \"sex\", \"capital_loss\"]\n",
    "top10_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\", \"hours_per_week\", \"education_num\", \"capital_gain\", \"education\", \"sex\", \"workclass\", \"capital_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-817f43cedb3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop3_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop3_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcat_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "top3_results = []\n",
    "for model, feats in top3_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([train.columns[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top3_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top3_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top3_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top3_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_scores = pd.DataFrame(top3_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.805527</td>\n",
       "      <td>0.851631</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.864625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.824770</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.857539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.769089</td>\n",
       "      <td>0.751890</td>\n",
       "      <td>0.760491</td>\n",
       "      <td>0.727796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.805527  0.851631  0.819652  0.864625\n",
       "tabnet    0.824770  0.864272  0.819652  0.857539\n",
       "xgboost   0.769089  0.751890  0.760491  0.727796"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.79592 |  0:00:12s\n",
      "epoch 1  | loss: 0.49582 |  0:00:25s\n",
      "epoch 2  | loss: 0.44158 |  0:00:40s\n",
      "epoch 3  | loss: 0.40275 |  0:00:53s\n",
      "epoch 4  | loss: 0.40626 |  0:01:05s\n",
      "epoch 5  | loss: 0.4009  |  0:01:18s\n",
      "epoch 6  | loss: 0.39774 |  0:01:30s\n",
      "epoch 7  | loss: 0.39294 |  0:01:43s\n",
      "epoch 8  | loss: 0.3906  |  0:01:57s\n",
      "epoch 9  | loss: 0.39566 |  0:02:17s\n",
      "epoch 10 | loss: 0.3941  |  0:02:54s\n",
      "epoch 11 | loss: 0.39292 |  0:03:31s\n",
      "epoch 12 | loss: 0.39145 |  0:04:11s\n",
      "epoch 13 | loss: 0.3886  |  0:04:34s\n",
      "epoch 14 | loss: 0.39061 |  0:05:00s\n",
      "epoch 15 | loss: 0.39403 |  0:05:23s\n",
      "epoch 16 | loss: 0.38763 |  0:05:47s\n",
      "epoch 17 | loss: 0.38817 |  0:06:08s\n",
      "epoch 18 | loss: 0.39708 |  0:06:32s\n",
      "epoch 19 | loss: 0.39374 |  0:06:56s\n",
      "epoch 20 | loss: 0.3895  |  0:07:21s\n",
      "epoch 21 | loss: 0.38912 |  0:07:45s\n",
      "epoch 22 | loss: 0.38642 |  0:08:08s\n",
      "epoch 23 | loss: 0.3847  |  0:08:33s\n",
      "epoch 24 | loss: 0.38419 |  0:08:57s\n",
      "epoch 25 | loss: 0.38397 |  0:09:20s\n",
      "epoch 26 | loss: 0.38094 |  0:09:44s\n",
      "epoch 27 | loss: 0.38124 |  0:10:07s\n",
      "epoch 28 | loss: 0.38337 |  0:10:31s\n",
      "epoch 29 | loss: 0.38498 |  0:10:55s\n",
      "epoch 30 | loss: 0.38105 |  0:11:19s\n",
      "epoch 31 | loss: 0.38232 |  0:11:40s\n",
      "epoch 32 | loss: 0.3815  |  0:12:04s\n",
      "epoch 33 | loss: 0.38328 |  0:12:26s\n",
      "epoch 34 | loss: 0.37821 |  0:12:49s\n",
      "epoch 35 | loss: 0.3803  |  0:13:13s\n",
      "epoch 36 | loss: 0.37915 |  0:13:36s\n",
      "epoch 37 | loss: 0.37989 |  0:13:59s\n",
      "epoch 38 | loss: 0.39247 |  0:14:23s\n",
      "epoch 39 | loss: 0.3804  |  0:14:46s\n",
      "epoch 40 | loss: 0.37794 |  0:15:11s\n",
      "epoch 41 | loss: 0.37671 |  0:15:32s\n",
      "epoch 42 | loss: 0.37527 |  0:15:54s\n",
      "epoch 43 | loss: 0.37477 |  0:16:15s\n",
      "epoch 44 | loss: 0.38458 |  0:16:38s\n",
      "epoch 45 | loss: 0.38768 |  0:17:00s\n",
      "epoch 46 | loss: 0.37762 |  0:17:25s\n",
      "epoch 47 | loss: 0.37628 |  0:17:48s\n",
      "epoch 48 | loss: 0.37779 |  0:18:10s\n",
      "epoch 49 | loss: 0.37808 |  0:18:33s\n",
      "epoch 50 | loss: 0.37675 |  0:18:56s\n",
      "epoch 51 | loss: 0.37481 |  0:19:20s\n",
      "epoch 52 | loss: 0.37458 |  0:19:43s\n",
      "epoch 53 | loss: 0.37851 |  0:20:06s\n",
      "epoch 54 | loss: 0.37758 |  0:20:30s\n",
      "epoch 55 | loss: 0.38001 |  0:20:51s\n",
      "epoch 56 | loss: 0.38308 |  0:21:15s\n",
      "epoch 57 | loss: 0.38137 |  0:21:39s\n",
      "epoch 58 | loss: 0.37925 |  0:22:01s\n",
      "epoch 59 | loss: 0.38585 |  0:22:24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:08] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:42:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.90432 |  0:00:23s\n",
      "epoch 1  | loss: 0.39276 |  0:00:49s\n",
      "epoch 2  | loss: 0.34943 |  0:01:11s\n",
      "epoch 3  | loss: 0.34461 |  0:01:34s\n",
      "epoch 4  | loss: 0.34024 |  0:01:57s\n",
      "epoch 5  | loss: 0.34186 |  0:02:20s\n",
      "epoch 6  | loss: 0.34383 |  0:02:42s\n",
      "epoch 7  | loss: 0.33729 |  0:03:08s\n",
      "epoch 8  | loss: 0.33883 |  0:03:30s\n",
      "epoch 9  | loss: 0.33975 |  0:03:54s\n",
      "epoch 10 | loss: 0.34485 |  0:04:17s\n",
      "epoch 11 | loss: 0.33227 |  0:04:40s\n",
      "epoch 12 | loss: 0.33144 |  0:05:06s\n",
      "epoch 13 | loss: 0.3314  |  0:05:29s\n",
      "epoch 14 | loss: 0.33928 |  0:05:50s\n",
      "epoch 15 | loss: 0.32989 |  0:06:12s\n",
      "epoch 16 | loss: 0.33309 |  0:06:33s\n",
      "epoch 17 | loss: 0.33441 |  0:06:56s\n",
      "epoch 18 | loss: 0.33631 |  0:07:21s\n",
      "epoch 19 | loss: 0.32965 |  0:07:44s\n",
      "epoch 20 | loss: 0.33031 |  0:08:08s\n",
      "epoch 21 | loss: 0.32679 |  0:08:31s\n",
      "epoch 22 | loss: 0.32387 |  0:08:53s\n",
      "epoch 23 | loss: 0.32129 |  0:09:18s\n",
      "epoch 24 | loss: 0.3256  |  0:09:40s\n",
      "epoch 25 | loss: 0.33124 |  0:10:03s\n",
      "epoch 26 | loss: 0.32599 |  0:10:26s\n",
      "epoch 27 | loss: 0.32683 |  0:10:49s\n",
      "epoch 28 | loss: 0.32928 |  0:11:12s\n",
      "epoch 29 | loss: 0.32668 |  0:11:35s\n",
      "epoch 30 | loss: 0.32345 |  0:11:58s\n",
      "epoch 31 | loss: 0.32416 |  0:12:21s\n",
      "epoch 32 | loss: 0.32507 |  0:12:43s\n",
      "epoch 33 | loss: 0.32404 |  0:13:05s\n",
      "epoch 34 | loss: 0.32054 |  0:13:29s\n",
      "epoch 35 | loss: 0.32212 |  0:13:53s\n",
      "epoch 36 | loss: 0.32217 |  0:14:14s\n",
      "epoch 37 | loss: 0.31913 |  0:14:37s\n",
      "epoch 38 | loss: 0.32162 |  0:15:00s\n",
      "epoch 39 | loss: 0.32277 |  0:15:23s\n",
      "epoch 40 | loss: 0.31707 |  0:15:46s\n",
      "epoch 41 | loss: 0.31975 |  0:16:09s\n",
      "epoch 42 | loss: 0.3171  |  0:16:31s\n",
      "epoch 43 | loss: 0.32048 |  0:16:55s\n",
      "epoch 44 | loss: 0.32208 |  0:17:17s\n",
      "epoch 45 | loss: 0.31896 |  0:17:41s\n",
      "epoch 46 | loss: 0.31771 |  0:18:03s\n",
      "epoch 47 | loss: 0.32248 |  0:18:25s\n",
      "epoch 48 | loss: 0.31958 |  0:18:48s\n",
      "epoch 49 | loss: 0.31565 |  0:19:12s\n",
      "epoch 50 | loss: 0.32475 |  0:19:35s\n",
      "epoch 51 | loss: 0.32692 |  0:20:00s\n",
      "epoch 52 | loss: 0.32314 |  0:20:21s\n",
      "epoch 53 | loss: 0.31824 |  0:20:44s\n",
      "epoch 54 | loss: 0.3168  |  0:21:06s\n",
      "epoch 55 | loss: 0.3186  |  0:21:29s\n",
      "epoch 56 | loss: 0.3175  |  0:21:51s\n",
      "epoch 57 | loss: 0.32138 |  0:22:14s\n",
      "epoch 58 | loss: 0.31531 |  0:22:37s\n",
      "epoch 59 | loss: 0.32162 |  0:22:59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.88531 |  0:00:22s\n",
      "epoch 1  | loss: 0.45036 |  0:00:46s\n",
      "epoch 2  | loss: 0.38011 |  0:01:11s\n",
      "epoch 3  | loss: 0.37047 |  0:01:34s\n",
      "epoch 4  | loss: 0.36544 |  0:01:56s\n",
      "epoch 5  | loss: 0.35333 |  0:02:18s\n",
      "epoch 6  | loss: 0.34735 |  0:02:40s\n",
      "epoch 7  | loss: 0.34333 |  0:03:04s\n",
      "epoch 8  | loss: 0.33326 |  0:03:26s\n",
      "epoch 9  | loss: 0.33396 |  0:03:48s\n",
      "epoch 10 | loss: 0.3291  |  0:04:10s\n",
      "epoch 11 | loss: 0.33335 |  0:04:33s\n",
      "epoch 12 | loss: 0.33609 |  0:04:56s\n",
      "epoch 13 | loss: 0.3272  |  0:05:22s\n",
      "epoch 14 | loss: 0.32744 |  0:05:46s\n",
      "epoch 15 | loss: 0.32778 |  0:06:08s\n",
      "epoch 16 | loss: 0.33217 |  0:06:31s\n",
      "epoch 17 | loss: 0.33119 |  0:06:55s\n",
      "epoch 18 | loss: 0.32972 |  0:07:19s\n",
      "epoch 19 | loss: 0.32382 |  0:07:44s\n",
      "epoch 20 | loss: 0.32044 |  0:08:07s\n",
      "epoch 21 | loss: 0.32228 |  0:08:31s\n",
      "epoch 22 | loss: 0.32318 |  0:08:53s\n",
      "epoch 23 | loss: 0.31931 |  0:09:17s\n",
      "epoch 24 | loss: 0.31832 |  0:09:43s\n",
      "epoch 25 | loss: 0.32146 |  0:10:08s\n",
      "epoch 26 | loss: 0.31939 |  0:10:31s\n",
      "epoch 27 | loss: 0.32324 |  0:10:54s\n",
      "epoch 28 | loss: 0.32076 |  0:11:16s\n",
      "epoch 29 | loss: 0.31843 |  0:11:41s\n",
      "epoch 30 | loss: 0.32007 |  0:12:03s\n",
      "epoch 31 | loss: 0.31646 |  0:12:26s\n",
      "epoch 32 | loss: 0.31788 |  0:12:49s\n",
      "epoch 33 | loss: 0.32226 |  0:13:11s\n",
      "epoch 34 | loss: 0.32327 |  0:13:36s\n",
      "epoch 35 | loss: 0.31879 |  0:14:00s\n",
      "epoch 36 | loss: 0.32053 |  0:14:22s\n",
      "epoch 37 | loss: 0.31749 |  0:14:44s\n",
      "epoch 38 | loss: 0.31663 |  0:15:06s\n",
      "epoch 39 | loss: 0.31701 |  0:15:29s\n",
      "epoch 40 | loss: 0.31846 |  0:15:54s\n",
      "epoch 41 | loss: 0.31558 |  0:16:17s\n",
      "epoch 42 | loss: 0.31806 |  0:16:39s\n",
      "epoch 43 | loss: 0.3132  |  0:17:01s\n",
      "epoch 44 | loss: 0.31541 |  0:17:24s\n",
      "epoch 45 | loss: 0.31546 |  0:17:46s\n",
      "epoch 46 | loss: 0.31311 |  0:18:12s\n",
      "epoch 47 | loss: 0.31327 |  0:18:35s\n",
      "epoch 48 | loss: 0.3125  |  0:18:59s\n",
      "epoch 49 | loss: 0.31129 |  0:19:23s\n",
      "epoch 50 | loss: 0.31289 |  0:19:46s\n",
      "epoch 51 | loss: 0.31092 |  0:20:12s\n",
      "epoch 52 | loss: 0.31229 |  0:20:36s\n",
      "epoch 53 | loss: 0.31126 |  0:20:58s\n",
      "epoch 54 | loss: 0.309   |  0:21:20s\n",
      "epoch 55 | loss: 0.31072 |  0:21:42s\n",
      "epoch 56 | loss: 0.31349 |  0:22:05s\n",
      "epoch 57 | loss: 0.3108  |  0:22:29s\n",
      "epoch 58 | loss: 0.31376 |  0:22:51s\n",
      "epoch 59 | loss: 0.32204 |  0:23:14s\n"
     ]
    }
   ],
   "source": [
    "top10_results = []\n",
    "for model, feats in top10_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([column_names[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top10_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top10_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top10_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top10_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_scores = pd.DataFrame(top10_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.856704</td>\n",
       "      <td>0.909560</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.913265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.911028</td>\n",
       "      <td>0.869396</td>\n",
       "      <td>0.916778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.826612</td>\n",
       "      <td>0.851441</td>\n",
       "      <td>0.835619</td>\n",
       "      <td>0.867916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.856704  0.909560  0.857318  0.913265\n",
       "tabnet    0.859570  0.911028  0.869396  0.916778\n",
       "xgboost   0.826612  0.851441  0.835619  0.867916"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
