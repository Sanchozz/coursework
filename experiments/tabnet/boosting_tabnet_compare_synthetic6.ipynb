{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pickle\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "from bo_parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tuned = {\n",
    "    \"learning_rate\" : 0.1911040149797038, \n",
    "    \"max_depth\" : 6, \n",
    "    \"n_estimators\" : 875\n",
    "}\n",
    "# lgbm_tuned += LIGHTGBM_PARAMS\n",
    "\n",
    "xgb_tuned = {\n",
    "    \"learning_rate\" : 0.103989684658078, \n",
    "    \"max_depth\" : 5, \n",
    "    \"n_estimators\" : 805\n",
    "}\n",
    "# xgb_tuned += XGBOOST_PARAMS\n",
    "\n",
    "tabnet_tuned = {\n",
    "    \"gamma\" : 1.595496549887517, \n",
    "    \"lambda_sparse\" : 0.08691860857137684, \n",
    "    \"n_steps\" : 3,\n",
    "    \"n_a\" : 16,\n",
    "    \"momentum\" : 0.6,\n",
    "}\n",
    "tabnet_tuned[\"n_d\"] = tabnet_tuned[\"n_a\"]\n",
    "\n",
    "tabnet_paper = {\n",
    "    \"gamma\" : 1.5, \n",
    "    \"lambda_sparse\" : 0.005, \n",
    "    \"n_steps\" : 5,\n",
    "    \"n_a\" : 16,\n",
    "    \"momentum\" : 0.7,\n",
    "}\n",
    "tabnet_paper[\"n_d\"] = tabnet_paper[\"n_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/synthetic/syn6/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/synthetic/syn6/train.csv\")\n",
    "valid = pd.read_csv(\"data/synthetic/syn6/val.csv\")\n",
    "test = pd.read_csv(\"data/synthetic/syn6/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.778443</td>\n",
       "      <td>1.556836</td>\n",
       "      <td>-2.240387</td>\n",
       "      <td>2.026489</td>\n",
       "      <td>1.485604</td>\n",
       "      <td>-0.062436</td>\n",
       "      <td>0.777644</td>\n",
       "      <td>0.048588</td>\n",
       "      <td>-0.246622</td>\n",
       "      <td>0.514226</td>\n",
       "      <td>4.717438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.841860</td>\n",
       "      <td>-0.979136</td>\n",
       "      <td>1.256012</td>\n",
       "      <td>0.705875</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>-0.979136</td>\n",
       "      <td>1.256012</td>\n",
       "      <td>0.705875</td>\n",
       "      <td>-0.625118</td>\n",
       "      <td>-0.071520</td>\n",
       "      <td>-2.408301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.710729</td>\n",
       "      <td>1.281635</td>\n",
       "      <td>0.722144</td>\n",
       "      <td>0.492872</td>\n",
       "      <td>0.710729</td>\n",
       "      <td>1.281635</td>\n",
       "      <td>0.722144</td>\n",
       "      <td>0.492872</td>\n",
       "      <td>-1.171956</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>-2.160284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.139451</td>\n",
       "      <td>0.837196</td>\n",
       "      <td>0.704511</td>\n",
       "      <td>0.665432</td>\n",
       "      <td>-0.139451</td>\n",
       "      <td>0.837196</td>\n",
       "      <td>0.704511</td>\n",
       "      <td>0.665432</td>\n",
       "      <td>-0.813686</td>\n",
       "      <td>1.088007</td>\n",
       "      <td>-2.635003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.221065</td>\n",
       "      <td>-1.041700</td>\n",
       "      <td>0.761553</td>\n",
       "      <td>1.912647</td>\n",
       "      <td>-2.297631</td>\n",
       "      <td>0.834077</td>\n",
       "      <td>-1.146009</td>\n",
       "      <td>-2.817934</td>\n",
       "      <td>0.107312</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>3.724639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1        X2        X3        X4        X5        X6  \\\n",
       "0  0.778443  1.556836 -2.240387  2.026489  1.485604 -0.062436  0.777644   \n",
       "1  0.841860 -0.979136  1.256012  0.705875  0.841860 -0.979136  1.256012   \n",
       "2  0.710729  1.281635  0.722144  0.492872  0.710729  1.281635  0.722144   \n",
       "3 -0.139451  0.837196  0.704511  0.665432 -0.139451  0.837196  0.704511   \n",
       "4 -0.221065 -1.041700  0.761553  1.912647 -2.297631  0.834077 -1.146009   \n",
       "\n",
       "         X7        X8        X9       X10  TARGET  \n",
       "0  0.048588 -0.246622  0.514226  4.717438       0  \n",
       "1  0.705875 -0.625118 -0.071520 -2.408301       0  \n",
       "2  0.492872 -1.171956  0.022033 -2.160284       0  \n",
       "3  0.665432 -0.813686  1.088007 -2.635003       0  \n",
       "4 -2.817934  0.107312  0.021818  3.724639       0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop([\"TARGET\"], axis=1)\n",
    "train_y = train[\"TARGET\"]\n",
    "\n",
    "test_X = test.drop([\"TARGET\"], axis=1)\n",
    "test_y = test[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.1911040149797038, max_depth=6, metric='auc',\n",
       "               n_estimators=875, objective='binary', random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier(**{**lgbm_tuned, **LIGHTGBM_PARAMS})\n",
    "model_lgbm.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:54:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.103989684658078, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=805, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=True,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "model_xgb.fit(train_X, train_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABNET_PARAMS[\"verbose\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.70537 |  0:00:00s\n",
      "epoch 1  | loss: 0.44639 |  0:00:01s\n",
      "epoch 2  | loss: 0.33945 |  0:00:02s\n",
      "epoch 3  | loss: 0.28873 |  0:00:03s\n",
      "epoch 4  | loss: 0.2638  |  0:00:04s\n",
      "epoch 5  | loss: 0.25071 |  0:00:05s\n",
      "epoch 6  | loss: 0.23879 |  0:00:06s\n",
      "epoch 7  | loss: 0.21813 |  0:00:06s\n",
      "epoch 8  | loss: 0.21971 |  0:00:07s\n",
      "epoch 9  | loss: 0.19948 |  0:00:08s\n",
      "epoch 10 | loss: 0.19595 |  0:00:09s\n",
      "epoch 11 | loss: 0.18277 |  0:00:10s\n",
      "epoch 12 | loss: 0.17442 |  0:00:11s\n",
      "epoch 13 | loss: 0.18497 |  0:00:12s\n",
      "epoch 14 | loss: 0.1843  |  0:00:12s\n",
      "epoch 15 | loss: 0.18143 |  0:00:13s\n",
      "epoch 16 | loss: 0.16993 |  0:00:14s\n",
      "epoch 17 | loss: 0.16224 |  0:00:15s\n",
      "epoch 18 | loss: 0.15616 |  0:00:16s\n",
      "epoch 19 | loss: 0.14214 |  0:00:17s\n",
      "epoch 20 | loss: 0.14416 |  0:00:18s\n",
      "epoch 21 | loss: 0.14084 |  0:00:19s\n",
      "epoch 22 | loss: 0.14086 |  0:00:20s\n",
      "epoch 23 | loss: 0.14183 |  0:00:21s\n",
      "epoch 24 | loss: 0.14549 |  0:00:22s\n",
      "epoch 25 | loss: 0.14371 |  0:00:23s\n",
      "epoch 26 | loss: 0.14233 |  0:00:24s\n",
      "epoch 27 | loss: 0.13432 |  0:00:24s\n",
      "epoch 28 | loss: 0.13152 |  0:00:25s\n",
      "epoch 29 | loss: 0.12353 |  0:00:26s\n",
      "epoch 30 | loss: 0.12922 |  0:00:27s\n",
      "epoch 31 | loss: 0.13259 |  0:00:29s\n",
      "epoch 32 | loss: 0.1253  |  0:00:30s\n",
      "epoch 33 | loss: 0.11996 |  0:00:31s\n",
      "epoch 34 | loss: 0.12416 |  0:00:31s\n",
      "epoch 35 | loss: 0.1278  |  0:00:32s\n",
      "epoch 36 | loss: 0.12885 |  0:00:33s\n",
      "epoch 37 | loss: 0.13269 |  0:00:34s\n",
      "epoch 38 | loss: 0.13899 |  0:00:35s\n",
      "epoch 39 | loss: 0.12255 |  0:00:36s\n",
      "epoch 40 | loss: 0.13127 |  0:00:37s\n",
      "epoch 41 | loss: 0.13247 |  0:00:37s\n",
      "epoch 42 | loss: 0.12989 |  0:00:38s\n",
      "epoch 43 | loss: 0.12611 |  0:00:39s\n",
      "epoch 44 | loss: 0.13553 |  0:00:40s\n",
      "epoch 45 | loss: 0.13248 |  0:00:41s\n",
      "epoch 46 | loss: 0.12661 |  0:00:42s\n",
      "epoch 47 | loss: 0.12377 |  0:00:43s\n",
      "epoch 48 | loss: 0.12688 |  0:00:44s\n",
      "epoch 49 | loss: 0.12281 |  0:00:44s\n",
      "epoch 50 | loss: 0.12766 |  0:00:45s\n",
      "epoch 51 | loss: 0.12046 |  0:00:46s\n",
      "epoch 52 | loss: 0.11521 |  0:00:47s\n",
      "epoch 53 | loss: 0.11597 |  0:00:48s\n",
      "epoch 54 | loss: 0.11677 |  0:00:49s\n",
      "epoch 55 | loss: 0.11397 |  0:00:50s\n",
      "epoch 56 | loss: 0.12206 |  0:00:50s\n",
      "epoch 57 | loss: 0.11891 |  0:00:51s\n",
      "epoch 58 | loss: 0.12886 |  0:00:52s\n",
      "epoch 59 | loss: 0.13278 |  0:00:53s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS})\n",
    "model_tabnet.fit(train_X.values, train_y.values, max_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.94348 |  0:00:01s\n",
      "epoch 1  | loss: 0.57147 |  0:00:02s\n",
      "epoch 2  | loss: 0.53987 |  0:00:03s\n",
      "epoch 3  | loss: 0.4866  |  0:00:04s\n",
      "epoch 4  | loss: 0.44832 |  0:00:05s\n",
      "epoch 5  | loss: 0.40707 |  0:00:06s\n",
      "epoch 6  | loss: 0.38517 |  0:00:07s\n",
      "epoch 7  | loss: 0.36874 |  0:00:08s\n",
      "epoch 8  | loss: 0.33914 |  0:00:10s\n",
      "epoch 9  | loss: 0.31663 |  0:00:11s\n",
      "epoch 10 | loss: 0.30497 |  0:00:12s\n",
      "epoch 11 | loss: 0.29231 |  0:00:13s\n",
      "epoch 12 | loss: 0.29166 |  0:00:14s\n",
      "epoch 13 | loss: 0.28187 |  0:00:15s\n",
      "epoch 14 | loss: 0.27122 |  0:00:16s\n",
      "epoch 15 | loss: 0.25751 |  0:00:17s\n",
      "epoch 16 | loss: 0.24802 |  0:00:19s\n",
      "epoch 17 | loss: 0.24082 |  0:00:20s\n",
      "epoch 18 | loss: 0.23109 |  0:00:21s\n",
      "epoch 19 | loss: 0.2155  |  0:00:22s\n",
      "epoch 20 | loss: 0.21516 |  0:00:23s\n",
      "epoch 21 | loss: 0.20467 |  0:00:24s\n",
      "epoch 22 | loss: 0.20548 |  0:00:25s\n",
      "epoch 23 | loss: 0.18949 |  0:00:26s\n",
      "epoch 24 | loss: 0.18049 |  0:00:27s\n",
      "epoch 25 | loss: 0.17588 |  0:00:29s\n",
      "epoch 26 | loss: 0.17601 |  0:00:30s\n",
      "epoch 27 | loss: 0.16495 |  0:00:31s\n",
      "epoch 28 | loss: 0.16226 |  0:00:32s\n",
      "epoch 29 | loss: 0.15714 |  0:00:33s\n",
      "epoch 30 | loss: 0.15618 |  0:00:34s\n",
      "epoch 31 | loss: 0.15035 |  0:00:35s\n",
      "epoch 32 | loss: 0.15734 |  0:00:36s\n",
      "epoch 33 | loss: 0.15275 |  0:00:37s\n",
      "epoch 34 | loss: 0.15082 |  0:00:38s\n",
      "epoch 35 | loss: 0.14939 |  0:00:40s\n",
      "epoch 36 | loss: 0.15678 |  0:00:41s\n",
      "epoch 37 | loss: 0.15396 |  0:00:42s\n",
      "epoch 38 | loss: 0.15094 |  0:00:43s\n",
      "epoch 39 | loss: 0.15001 |  0:00:44s\n",
      "epoch 40 | loss: 0.14588 |  0:00:45s\n",
      "epoch 41 | loss: 0.14658 |  0:00:46s\n",
      "epoch 42 | loss: 0.1521  |  0:00:47s\n",
      "epoch 43 | loss: 0.15436 |  0:00:48s\n",
      "epoch 44 | loss: 0.14817 |  0:00:50s\n",
      "epoch 45 | loss: 0.14382 |  0:00:51s\n",
      "epoch 46 | loss: 0.13554 |  0:00:52s\n",
      "epoch 47 | loss: 0.13567 |  0:00:53s\n",
      "epoch 48 | loss: 0.12388 |  0:00:54s\n",
      "epoch 49 | loss: 0.12996 |  0:00:55s\n",
      "epoch 50 | loss: 0.13268 |  0:00:56s\n",
      "epoch 51 | loss: 0.13996 |  0:00:57s\n",
      "epoch 52 | loss: 0.13503 |  0:00:58s\n",
      "epoch 53 | loss: 0.13655 |  0:01:00s\n",
      "epoch 54 | loss: 0.13698 |  0:01:01s\n",
      "epoch 55 | loss: 0.13113 |  0:01:02s\n",
      "epoch 56 | loss: 0.12652 |  0:01:03s\n",
      "epoch 57 | loss: 0.12015 |  0:01:04s\n",
      "epoch 58 | loss: 0.11807 |  0:01:05s\n",
      "epoch 59 | loss: 0.11458 |  0:01:06s\n"
     ]
    }
   ],
   "source": [
    "model_tabnet_paper = TabNetClassifier(**{**tabnet_paper, **TABNET_PARAMS})\n",
    "model_tabnet_paper.fit(train_X.values, train_y.values, max_epochs=60, batch_size=3000, virtual_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet, f)\n",
    "with open('model_tabnet_paper.pickle', 'wb') as f:\n",
    "    pickle.dump(model_tabnet_paper, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_tabnet.pickle', 'rb') as f:\n",
    "    model_tabnet = pickle.load(f)\n",
    "with open('model_tabnet_paper.pickle', 'rb') as f:\n",
    "    model_tabnet_paper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM auc:  0.996656\n",
      "XGBoost auc:  0.996943\n",
      "TabNet auc:  0.988625\n",
      "TabNet Paper auc:  0.989876\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM auc: \", round(roc_auc_score(test_y, model_lgbm.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"XGBoost auc: \", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X)[:, 1]), 6))\n",
    "print(\"TabNet auc: \", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X.values)[:, 1]), 6))\n",
    "print(\"TabNet Paper auc: \", round(roc_auc_score(test_y, model_tabnet_paper.predict_proba(test_X.values)[:, 1]), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM acc:  0.973351\n",
      "XGBoost acc:  0.97535\n",
      "TabNet acc:  0.952032\n",
      "TabNet Paper acc:  0.956696\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM acc: \", round(accuracy_score(test_y, model_lgbm.predict(test_X)), 6))\n",
    "print(\"XGBoost acc: \", round(accuracy_score(test_y, model_xgb.predict(test_X)), 6))\n",
    "print(\"TabNet acc: \", round(accuracy_score(test_y, model_tabnet.predict(test_X.values)), 6))\n",
    "print(\"TabNet Paper acc: \", round(accuracy_score(test_y, model_tabnet_paper.predict(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM log_loss:  0.145076\n",
      "XGBoost log_loss:  0.070251\n",
      "TabNet log_loss:  0.135422\n",
      "TabNet Paper log_loss:  0.112501\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM log_loss: \", round(log_loss(test_y, model_lgbm.predict_proba(test_X)), 6))\n",
    "print(\"XGBoost log_loss: \", round(log_loss(test_y, model_xgb.predict_proba(test_X)), 6))\n",
    "print(\"TabNet log_loss: \", round(log_loss(test_y, model_tabnet.predict_proba(test_X.values)), 6))\n",
    "print(\"TabNet Paper log_loss: \", round(log_loss(test_y, model_tabnet_paper.predict_proba(test_X.values)), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = list(enumerate(model_lgbm.feature_importances_))\n",
    "importance_xgb = model_xgb.get_booster().get_score(importance_type='weight').items()\n",
    "importance_tabnet = list(enumerate(model_tabnet.feature_importances_))\n",
    "importance_tabnet_paper = list(enumerate(model_tabnet_paper.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_lgbm = sorted(importance_lgbm, key=lambda x: x[1], reverse=True)\n",
    "importance_xgb = sorted(importance_xgb, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet = sorted(importance_tabnet, key=lambda x: x[1], reverse=True)\n",
    "importance_tabnet_paper = sorted(importance_tabnet_paper, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x424.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = shap.TreeExplainer(model_xgb).shap_values(train_X)\n",
    "shap.summary_plot(shap_values, train_X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = pd.DataFrame([train.columns[x[0]] for x in importance_lgbm], columns=[\"LightGBM\"])\n",
    "df_compare[\"XGBoost\"] = [x[0] for x in importance_xgb]\n",
    "df_compare[\"SHAP_XGBoost\"] = train_X.columns[np.argsort(np.abs(shap_values).mean(0))][::-1]\n",
    "df_compare[\"TabNet\"] = [train.columns[x[0]] for x in importance_tabnet]\n",
    "df_compare[\"TabNet_Paper\"] = [train.columns[x[0]] for x in importance_tabnet_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "      <td>X10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X0</td>\n",
       "      <td>X1</td>\n",
       "      <td>X2</td>\n",
       "      <td>X2</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X1</td>\n",
       "      <td>X0</td>\n",
       "      <td>X1</td>\n",
       "      <td>X1</td>\n",
       "      <td>X6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X2</td>\n",
       "      <td>X2</td>\n",
       "      <td>X0</td>\n",
       "      <td>X6</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X8</td>\n",
       "      <td>X8</td>\n",
       "      <td>X6</td>\n",
       "      <td>X4</td>\n",
       "      <td>X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X9</td>\n",
       "      <td>X9</td>\n",
       "      <td>X7</td>\n",
       "      <td>X0</td>\n",
       "      <td>X4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X3</td>\n",
       "      <td>X3</td>\n",
       "      <td>X9</td>\n",
       "      <td>X8</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X5</td>\n",
       "      <td>X7</td>\n",
       "      <td>X3</td>\n",
       "      <td>X9</td>\n",
       "      <td>X7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X7</td>\n",
       "      <td>X6</td>\n",
       "      <td>X8</td>\n",
       "      <td>X7</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X4</td>\n",
       "      <td>X5</td>\n",
       "      <td>X5</td>\n",
       "      <td>X5</td>\n",
       "      <td>X8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X6</td>\n",
       "      <td>X4</td>\n",
       "      <td>X4</td>\n",
       "      <td>X3</td>\n",
       "      <td>X5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LightGBM XGBoost SHAP_XGBoost TabNet TabNet_Paper\n",
       "0       X10     X10          X10    X10          X10\n",
       "1        X0      X1           X2     X2           X2\n",
       "2        X1      X0           X1     X1           X6\n",
       "3        X2      X2           X0     X6           X1\n",
       "4        X8      X8           X6     X4           X0\n",
       "5        X9      X9           X7     X0           X4\n",
       "6        X3      X3           X9     X8           X9\n",
       "7        X5      X7           X3     X9           X7\n",
       "8        X7      X6           X8     X7           X3\n",
       "9        X4      X5           X5     X5           X8\n",
       "10       X6      X4           X4     X3           X5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:2, col1]) & set(df_compare.loc[:2, col2])))\n",
    "        top_3.append(d)\n",
    "top_3_data = pd.DataFrame(top_3, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             3             2       2             1        3\n",
       "SHAP_XGBoost         2             3       3             2        2\n",
       "TabNet               2             3       3             2        2\n",
       "TabNet_Paper         1             2       2             3        1\n",
       "XGBoost              3             2       2             1        3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 3 признака из каждой и обучить бустинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:4, col1]) & set(df_compare.loc[:4, col2])))\n",
    "        top_5.append(d)\n",
    "top_5_data = pd.DataFrame(top_5, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM             5             4       3             4        5\n",
       "SHAP_XGBoost         4             5       4             5        4\n",
       "TabNet               3             4       5             4        3\n",
       "TabNet_Paper         4             5       4             5        4\n",
       "XGBoost              5             4       3             4        5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_5_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = []\n",
    "\n",
    "for i in range(len(df_compare.columns)):\n",
    "    for j in range(len(df_compare.columns)):\n",
    "        col1 = df_compare.columns[i]\n",
    "        col2 = df_compare.columns[j]\n",
    "        d = []\n",
    "        d.append(col1)\n",
    "        d.append(col2)\n",
    "        d.append(len(set(df_compare.loc[:9, col1]) & set(df_compare.loc[:9, col2])))\n",
    "        top_10.append(d)\n",
    "top_10_data = pd.DataFrame(top_10, columns=[\"Model1\", \"Model2\", \"Sim\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model2</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAP_XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabNet_Paper</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model2        LightGBM  SHAP_XGBoost  TabNet  TabNet_Paper  XGBoost\n",
       "Model1                                                             \n",
       "LightGBM            10             9       9             9        9\n",
       "SHAP_XGBoost         9            10       9             9       10\n",
       "TabNet               9             9      10             9        9\n",
       "TabNet_Paper         9             9       9            10        9\n",
       "XGBoost              9            10       9             9       10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_data, values='Sim', index=['Model1'], columns=['Model2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_feats = {}\n",
    "top3_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\"]\n",
    "top3_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\"]\n",
    "top3_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_feats = {}\n",
    "top10_feats[\"xgboost\"] = [\"fnlwgt\", \"age\", \"hours_per_week\", \"occupation\", \"education_num\", \"capital_gain\", \"education\", \"workclass\", \"capital_loss\", \"native_country\"]\n",
    "top10_feats[\"shap\"] = [\"age\", \"martial_status\", \"capital_gain\", \"relationship\", \"education_num\", \"occupation\", \"fnlwgt\", \"hours_per_week\", \"sex\", \"capital_loss\"]\n",
    "top10_feats[\"tabnet\"] = [\"relationship\", \"age\", \"occupation\", \"hours_per_week\", \"education_num\", \"capital_gain\", \"education\", \"sex\", \"workclass\", \"capital_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-817f43cedb3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop3_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop3_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_X_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcat_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['fnlwgt', 'age', 'hours_per_week'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "top3_results = []\n",
    "for model, feats in top3_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([train.columns[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top3_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top3_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top3_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top3_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_scores = pd.DataFrame(top3_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.805527</td>\n",
       "      <td>0.851631</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.864625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.824770</td>\n",
       "      <td>0.864272</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>0.857539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.769089</td>\n",
       "      <td>0.751890</td>\n",
       "      <td>0.760491</td>\n",
       "      <td>0.727796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.805527  0.851631  0.819652  0.864625\n",
       "tabnet    0.824770  0.864272  0.819652  0.857539\n",
       "xgboost   0.769089  0.751890  0.760491  0.727796"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_3_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:31] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.79592 |  0:00:12s\n",
      "epoch 1  | loss: 0.49582 |  0:00:25s\n",
      "epoch 2  | loss: 0.44158 |  0:00:40s\n",
      "epoch 3  | loss: 0.40275 |  0:00:53s\n",
      "epoch 4  | loss: 0.40626 |  0:01:05s\n",
      "epoch 5  | loss: 0.4009  |  0:01:18s\n",
      "epoch 6  | loss: 0.39774 |  0:01:30s\n",
      "epoch 7  | loss: 0.39294 |  0:01:43s\n",
      "epoch 8  | loss: 0.3906  |  0:01:57s\n",
      "epoch 9  | loss: 0.39566 |  0:02:17s\n",
      "epoch 10 | loss: 0.3941  |  0:02:54s\n",
      "epoch 11 | loss: 0.39292 |  0:03:31s\n",
      "epoch 12 | loss: 0.39145 |  0:04:11s\n",
      "epoch 13 | loss: 0.3886  |  0:04:34s\n",
      "epoch 14 | loss: 0.39061 |  0:05:00s\n",
      "epoch 15 | loss: 0.39403 |  0:05:23s\n",
      "epoch 16 | loss: 0.38763 |  0:05:47s\n",
      "epoch 17 | loss: 0.38817 |  0:06:08s\n",
      "epoch 18 | loss: 0.39708 |  0:06:32s\n",
      "epoch 19 | loss: 0.39374 |  0:06:56s\n",
      "epoch 20 | loss: 0.3895  |  0:07:21s\n",
      "epoch 21 | loss: 0.38912 |  0:07:45s\n",
      "epoch 22 | loss: 0.38642 |  0:08:08s\n",
      "epoch 23 | loss: 0.3847  |  0:08:33s\n",
      "epoch 24 | loss: 0.38419 |  0:08:57s\n",
      "epoch 25 | loss: 0.38397 |  0:09:20s\n",
      "epoch 26 | loss: 0.38094 |  0:09:44s\n",
      "epoch 27 | loss: 0.38124 |  0:10:07s\n",
      "epoch 28 | loss: 0.38337 |  0:10:31s\n",
      "epoch 29 | loss: 0.38498 |  0:10:55s\n",
      "epoch 30 | loss: 0.38105 |  0:11:19s\n",
      "epoch 31 | loss: 0.38232 |  0:11:40s\n",
      "epoch 32 | loss: 0.3815  |  0:12:04s\n",
      "epoch 33 | loss: 0.38328 |  0:12:26s\n",
      "epoch 34 | loss: 0.37821 |  0:12:49s\n",
      "epoch 35 | loss: 0.3803  |  0:13:13s\n",
      "epoch 36 | loss: 0.37915 |  0:13:36s\n",
      "epoch 37 | loss: 0.37989 |  0:13:59s\n",
      "epoch 38 | loss: 0.39247 |  0:14:23s\n",
      "epoch 39 | loss: 0.3804  |  0:14:46s\n",
      "epoch 40 | loss: 0.37794 |  0:15:11s\n",
      "epoch 41 | loss: 0.37671 |  0:15:32s\n",
      "epoch 42 | loss: 0.37527 |  0:15:54s\n",
      "epoch 43 | loss: 0.37477 |  0:16:15s\n",
      "epoch 44 | loss: 0.38458 |  0:16:38s\n",
      "epoch 45 | loss: 0.38768 |  0:17:00s\n",
      "epoch 46 | loss: 0.37762 |  0:17:25s\n",
      "epoch 47 | loss: 0.37628 |  0:17:48s\n",
      "epoch 48 | loss: 0.37779 |  0:18:10s\n",
      "epoch 49 | loss: 0.37808 |  0:18:33s\n",
      "epoch 50 | loss: 0.37675 |  0:18:56s\n",
      "epoch 51 | loss: 0.37481 |  0:19:20s\n",
      "epoch 52 | loss: 0.37458 |  0:19:43s\n",
      "epoch 53 | loss: 0.37851 |  0:20:06s\n",
      "epoch 54 | loss: 0.37758 |  0:20:30s\n",
      "epoch 55 | loss: 0.38001 |  0:20:51s\n",
      "epoch 56 | loss: 0.38308 |  0:21:15s\n",
      "epoch 57 | loss: 0.38137 |  0:21:39s\n",
      "epoch 58 | loss: 0.37925 |  0:22:01s\n",
      "epoch 59 | loss: 0.38585 |  0:22:24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:08] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:42:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.90432 |  0:00:23s\n",
      "epoch 1  | loss: 0.39276 |  0:00:49s\n",
      "epoch 2  | loss: 0.34943 |  0:01:11s\n",
      "epoch 3  | loss: 0.34461 |  0:01:34s\n",
      "epoch 4  | loss: 0.34024 |  0:01:57s\n",
      "epoch 5  | loss: 0.34186 |  0:02:20s\n",
      "epoch 6  | loss: 0.34383 |  0:02:42s\n",
      "epoch 7  | loss: 0.33729 |  0:03:08s\n",
      "epoch 8  | loss: 0.33883 |  0:03:30s\n",
      "epoch 9  | loss: 0.33975 |  0:03:54s\n",
      "epoch 10 | loss: 0.34485 |  0:04:17s\n",
      "epoch 11 | loss: 0.33227 |  0:04:40s\n",
      "epoch 12 | loss: 0.33144 |  0:05:06s\n",
      "epoch 13 | loss: 0.3314  |  0:05:29s\n",
      "epoch 14 | loss: 0.33928 |  0:05:50s\n",
      "epoch 15 | loss: 0.32989 |  0:06:12s\n",
      "epoch 16 | loss: 0.33309 |  0:06:33s\n",
      "epoch 17 | loss: 0.33441 |  0:06:56s\n",
      "epoch 18 | loss: 0.33631 |  0:07:21s\n",
      "epoch 19 | loss: 0.32965 |  0:07:44s\n",
      "epoch 20 | loss: 0.33031 |  0:08:08s\n",
      "epoch 21 | loss: 0.32679 |  0:08:31s\n",
      "epoch 22 | loss: 0.32387 |  0:08:53s\n",
      "epoch 23 | loss: 0.32129 |  0:09:18s\n",
      "epoch 24 | loss: 0.3256  |  0:09:40s\n",
      "epoch 25 | loss: 0.33124 |  0:10:03s\n",
      "epoch 26 | loss: 0.32599 |  0:10:26s\n",
      "epoch 27 | loss: 0.32683 |  0:10:49s\n",
      "epoch 28 | loss: 0.32928 |  0:11:12s\n",
      "epoch 29 | loss: 0.32668 |  0:11:35s\n",
      "epoch 30 | loss: 0.32345 |  0:11:58s\n",
      "epoch 31 | loss: 0.32416 |  0:12:21s\n",
      "epoch 32 | loss: 0.32507 |  0:12:43s\n",
      "epoch 33 | loss: 0.32404 |  0:13:05s\n",
      "epoch 34 | loss: 0.32054 |  0:13:29s\n",
      "epoch 35 | loss: 0.32212 |  0:13:53s\n",
      "epoch 36 | loss: 0.32217 |  0:14:14s\n",
      "epoch 37 | loss: 0.31913 |  0:14:37s\n",
      "epoch 38 | loss: 0.32162 |  0:15:00s\n",
      "epoch 39 | loss: 0.32277 |  0:15:23s\n",
      "epoch 40 | loss: 0.31707 |  0:15:46s\n",
      "epoch 41 | loss: 0.31975 |  0:16:09s\n",
      "epoch 42 | loss: 0.3171  |  0:16:31s\n",
      "epoch 43 | loss: 0.32048 |  0:16:55s\n",
      "epoch 44 | loss: 0.32208 |  0:17:17s\n",
      "epoch 45 | loss: 0.31896 |  0:17:41s\n",
      "epoch 46 | loss: 0.31771 |  0:18:03s\n",
      "epoch 47 | loss: 0.32248 |  0:18:25s\n",
      "epoch 48 | loss: 0.31958 |  0:18:48s\n",
      "epoch 49 | loss: 0.31565 |  0:19:12s\n",
      "epoch 50 | loss: 0.32475 |  0:19:35s\n",
      "epoch 51 | loss: 0.32692 |  0:20:00s\n",
      "epoch 52 | loss: 0.32314 |  0:20:21s\n",
      "epoch 53 | loss: 0.31824 |  0:20:44s\n",
      "epoch 54 | loss: 0.3168  |  0:21:06s\n",
      "epoch 55 | loss: 0.3186  |  0:21:29s\n",
      "epoch 56 | loss: 0.3175  |  0:21:51s\n",
      "epoch 57 | loss: 0.32138 |  0:22:14s\n",
      "epoch 58 | loss: 0.31531 |  0:22:37s\n",
      "epoch 59 | loss: 0.32162 |  0:22:59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:22] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:05:22] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 0.88531 |  0:00:22s\n",
      "epoch 1  | loss: 0.45036 |  0:00:46s\n",
      "epoch 2  | loss: 0.38011 |  0:01:11s\n",
      "epoch 3  | loss: 0.37047 |  0:01:34s\n",
      "epoch 4  | loss: 0.36544 |  0:01:56s\n",
      "epoch 5  | loss: 0.35333 |  0:02:18s\n",
      "epoch 6  | loss: 0.34735 |  0:02:40s\n",
      "epoch 7  | loss: 0.34333 |  0:03:04s\n",
      "epoch 8  | loss: 0.33326 |  0:03:26s\n",
      "epoch 9  | loss: 0.33396 |  0:03:48s\n",
      "epoch 10 | loss: 0.3291  |  0:04:10s\n",
      "epoch 11 | loss: 0.33335 |  0:04:33s\n",
      "epoch 12 | loss: 0.33609 |  0:04:56s\n",
      "epoch 13 | loss: 0.3272  |  0:05:22s\n",
      "epoch 14 | loss: 0.32744 |  0:05:46s\n",
      "epoch 15 | loss: 0.32778 |  0:06:08s\n",
      "epoch 16 | loss: 0.33217 |  0:06:31s\n",
      "epoch 17 | loss: 0.33119 |  0:06:55s\n",
      "epoch 18 | loss: 0.32972 |  0:07:19s\n",
      "epoch 19 | loss: 0.32382 |  0:07:44s\n",
      "epoch 20 | loss: 0.32044 |  0:08:07s\n",
      "epoch 21 | loss: 0.32228 |  0:08:31s\n",
      "epoch 22 | loss: 0.32318 |  0:08:53s\n",
      "epoch 23 | loss: 0.31931 |  0:09:17s\n",
      "epoch 24 | loss: 0.31832 |  0:09:43s\n",
      "epoch 25 | loss: 0.32146 |  0:10:08s\n",
      "epoch 26 | loss: 0.31939 |  0:10:31s\n",
      "epoch 27 | loss: 0.32324 |  0:10:54s\n",
      "epoch 28 | loss: 0.32076 |  0:11:16s\n",
      "epoch 29 | loss: 0.31843 |  0:11:41s\n",
      "epoch 30 | loss: 0.32007 |  0:12:03s\n",
      "epoch 31 | loss: 0.31646 |  0:12:26s\n",
      "epoch 32 | loss: 0.31788 |  0:12:49s\n",
      "epoch 33 | loss: 0.32226 |  0:13:11s\n",
      "epoch 34 | loss: 0.32327 |  0:13:36s\n",
      "epoch 35 | loss: 0.31879 |  0:14:00s\n",
      "epoch 36 | loss: 0.32053 |  0:14:22s\n",
      "epoch 37 | loss: 0.31749 |  0:14:44s\n",
      "epoch 38 | loss: 0.31663 |  0:15:06s\n",
      "epoch 39 | loss: 0.31701 |  0:15:29s\n",
      "epoch 40 | loss: 0.31846 |  0:15:54s\n",
      "epoch 41 | loss: 0.31558 |  0:16:17s\n",
      "epoch 42 | loss: 0.31806 |  0:16:39s\n",
      "epoch 43 | loss: 0.3132  |  0:17:01s\n",
      "epoch 44 | loss: 0.31541 |  0:17:24s\n",
      "epoch 45 | loss: 0.31546 |  0:17:46s\n",
      "epoch 46 | loss: 0.31311 |  0:18:12s\n",
      "epoch 47 | loss: 0.31327 |  0:18:35s\n",
      "epoch 48 | loss: 0.3125  |  0:18:59s\n",
      "epoch 49 | loss: 0.31129 |  0:19:23s\n",
      "epoch 50 | loss: 0.31289 |  0:19:46s\n",
      "epoch 51 | loss: 0.31092 |  0:20:12s\n",
      "epoch 52 | loss: 0.31229 |  0:20:36s\n",
      "epoch 53 | loss: 0.31126 |  0:20:58s\n",
      "epoch 54 | loss: 0.309   |  0:21:20s\n",
      "epoch 55 | loss: 0.31072 |  0:21:42s\n",
      "epoch 56 | loss: 0.31349 |  0:22:05s\n",
      "epoch 57 | loss: 0.3108  |  0:22:29s\n",
      "epoch 58 | loss: 0.31376 |  0:22:51s\n",
      "epoch 59 | loss: 0.32204 |  0:23:14s\n"
     ]
    }
   ],
   "source": [
    "top10_results = []\n",
    "for model, feats in top10_feats.items():\n",
    "    train_X_slice = train_X[feats]\n",
    "    test_X_slice = test_X[feats]\n",
    "    cat_feats = set(train_X_slice.columns) & set([column_names[x] for x in categorical_idx])\n",
    "    cat_idx = sorted([list(train_X_slice.columns).index(x) for x in cat_feats])\n",
    "    cat_dims = [len(set(list(train_X_slice.iloc[:, x].unique()) + list(test_X_slice.iloc[:, x].unique()))) for x in cat_idx]\n",
    "    \n",
    "    model_xgb = XGBClassifier(**{**xgb_tuned, **XGBOOST_PARAMS})\n",
    "    model_xgb.fit(train_X_slice, train_y, verbose=1)\n",
    "    top10_results.append([model, \"XGBoost\", \"acc\", round(accuracy_score(test_y, model_xgb.predict(test_X_slice)), 6)])\n",
    "    top10_results.append([model, \"XGBoost\", \"auc\", round(roc_auc_score(test_y, model_xgb.predict_proba(test_X_slice)[:, 1]), 6)])\n",
    "    result = []\n",
    "    model_tabnet = TabNetClassifier(**{**tabnet_tuned, **TABNET_PARAMS}, cat_idxs=cat_idx, cat_dims=cat_dims)\n",
    "    model_tabnet.fit(train_X_slice.values, train_y.values, max_epochs=60)\n",
    "    top10_results.append([model, \"TabNet\", \"acc\", round(accuracy_score(test_y, model_tabnet.predict(test_X_slice.values)), 6)])\n",
    "    top10_results.append([model, \"TabNet\", \"auc\", round(roc_auc_score(test_y, model_tabnet.predict_proba(test_X_slice.values)[:, 1]), 6)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_scores = pd.DataFrame(top10_results, columns=[\"Features\", \"Model\", \"Score\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TabNet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">XGBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shap</th>\n",
       "      <td>0.856704</td>\n",
       "      <td>0.909560</td>\n",
       "      <td>0.857318</td>\n",
       "      <td>0.913265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tabnet</th>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.911028</td>\n",
       "      <td>0.869396</td>\n",
       "      <td>0.916778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.826612</td>\n",
       "      <td>0.851441</td>\n",
       "      <td>0.835619</td>\n",
       "      <td>0.867916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model       TabNet             XGBoost          \n",
       "Score          acc       auc       acc       auc\n",
       "Features                                        \n",
       "shap      0.856704  0.909560  0.857318  0.913265\n",
       "tabnet    0.859570  0.911028  0.869396  0.916778\n",
       "xgboost   0.826612  0.851441  0.835619  0.867916"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(top_10_scores, values='Value', index=['Features'], columns=['Model', \"Score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
